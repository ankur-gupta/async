{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Yet Another Tutorial \u00b6 Nearly every other tutorial, in our opinion 1 , has the same drawbacks: Study material is presented in the chronological order of invention Iterators Generators Generator-based coroutines Native coroutines Study material contains defunct concepts Study material uses insufficient terminology For many students, it is actually easier to first learn the basics of asynchronous programming in a modern language, like Go or Kotlin, and then come back to asynchronous programming in Python. This is because Go and Kotlin were designed to have asynchronous programming support very early on and therefore have a more streamlined learning experience. On the contrary, Python has acquired asynchronous programming via a series of superseding PEPs. As a result, some concepts have now become defunct (such as, generator-based coroutines) and some ideas need to be redefined (such as, the difference between iterators and generators). Teaching defunct concepts and obsolete definitions makes learning unnecessarily difficult. What this course does differently? \u00b6 We aim to bring the streamlined learning experience to Python. In this course, study material is presented in an increasing order of complexity instead of the chronological order of invention study material omits defunct concepts terminology is invented or borrowed from modern languages, as needed Course Requirements \u00b6 Proficiency in Python syntax Basic knowledge of Python data structures Time and patience Time commitment \u00b6 This course is divided into 4 chapters, shown as top-level tabs. Depending upon your previous experience with async programming (in any language), it may take you anywhere between 4 hours to 4 days to complete the material. Feel free to skip and return back to the material as needed. Python version \u00b6 This course describes Python 3.8.5 . Earlier Python versions may not work and are not recommended. Python async sytnax is still being refined. Specific examples from this course may need to be updated but the general concepts should apply to all later versions of Python. Let's begin \u00b6 We'll start with some commentary on why async Python programming is difficult to learn. Footnotes \u00b6 Apologies for the bluntness. We aim to be direct. Please take no offense. \u21a9","title":"Introduction"},{"location":"#yet-another-tutorial","text":"Nearly every other tutorial, in our opinion 1 , has the same drawbacks: Study material is presented in the chronological order of invention Iterators Generators Generator-based coroutines Native coroutines Study material contains defunct concepts Study material uses insufficient terminology For many students, it is actually easier to first learn the basics of asynchronous programming in a modern language, like Go or Kotlin, and then come back to asynchronous programming in Python. This is because Go and Kotlin were designed to have asynchronous programming support very early on and therefore have a more streamlined learning experience. On the contrary, Python has acquired asynchronous programming via a series of superseding PEPs. As a result, some concepts have now become defunct (such as, generator-based coroutines) and some ideas need to be redefined (such as, the difference between iterators and generators). Teaching defunct concepts and obsolete definitions makes learning unnecessarily difficult.","title":"Yet Another Tutorial"},{"location":"#what-this-course-does-differently","text":"We aim to bring the streamlined learning experience to Python. In this course, study material is presented in an increasing order of complexity instead of the chronological order of invention study material omits defunct concepts terminology is invented or borrowed from modern languages, as needed","title":"What this course does differently?"},{"location":"#course-requirements","text":"Proficiency in Python syntax Basic knowledge of Python data structures Time and patience","title":"Course Requirements"},{"location":"#time-commitment","text":"This course is divided into 4 chapters, shown as top-level tabs. Depending upon your previous experience with async programming (in any language), it may take you anywhere between 4 hours to 4 days to complete the material. Feel free to skip and return back to the material as needed.","title":"Time commitment"},{"location":"#python-version","text":"This course describes Python 3.8.5 . Earlier Python versions may not work and are not recommended. Python async sytnax is still being refined. Specific examples from this course may need to be updated but the general concepts should apply to all later versions of Python.","title":"Python version"},{"location":"#lets-begin","text":"We'll start with some commentary on why async Python programming is difficult to learn.","title":"Let's begin"},{"location":"#footnotes","text":"Apologies for the bluntness. We aim to be direct. Please take no offense. \u21a9","title":"Footnotes"},{"location":"why-is-it-difficult/","text":"Sync Python is easy but async Python is not \u00b6 Tip Some terminology on this page may not make sense just yet. Feel free to skip and return. Synchronous Python programming is easy. So easy that it is often used as the first programming language and sometimes criticized for being too easy. But, learning asynchronous programming in Python is unreasonably difficult. Async programming is inherently more complicated \u00b6 A regular program 1 has a single 2 control flow path that a programmer can mentally walk through in order to reason about the program. An asynchronous program often has multiple, implicit control flow paths. A programmer has to think about all the possible paths in order to properly reason about the program. This makes asynchronous programming inherently more complicated than regular programming, no matter the choice of programming language. Python's troubled history \u00b6 Python arrived at async programming in incremental steps spread out over roughly two decades. Since the addition of simple generators in 2001, Python has constantly updated the semantics and syntax associated with async programming. 2001 Simple generators were proposed for Python 2.2 via PEP 255 . 2020 Generator-based coroutines were removed from Python 3.10. Teaching resources that were once up-to-date became stale over time. Python programmers had to unlearn the stale semantics and then learn the then-new semantics multiple times. Unfortunately, this historical cruft is reflected in the teaching materials. Async Python programming is very often taught in the same order as the order of incremental feature addition, starting with iterators , then generators , then generator-based coroutines , and finally, native coroutines . This style of teaching may be acceptable for a History Of Python lesson but it is unnecessarily disorienting for an otherwise python proficient programmer. A prime example of this historical cruft is the concept of generator-based coroutines which are scheduled for removal. Generator-based coroutines have been superseded by native coroutines . Teaching generator-based coroutines only serves to confuse the async beginner. Outdated and insufficient terminology \u00b6 Async Python programming is taught using generators (aka semicoroutines ) and coroutines . The terms generators and coroutines are old. Generators Generators first appeared in 1975, were a prominent feature of the Icon programming language, and were the inspiration for Python's PEP 255 in 2001. Coroutines Coroutines were invented in 1958 and the first published explanation appeared in a 1963 paper by Melvin Conway 3 in context of the COBOL programming language and punch cards . Since their invention, coroutines have been implemented in many languages with the implementations differing from each other due to language-specific idiosyncrasies. As a result, the modern definition of a coroutine is a generalization 4 of all the different coroutine implementations. The general-purpose defintions of a generator and a coroutine are wholly insufficient when it comes to Python because they fail to properly distinguish between a Python generator and a Python (native) coroutine. Generators are considered a subset of coroutines and coroutines are considered an evolution of generators . While the preceding statement is historically correct, it is no longer applicable because Python generators and Python (native) coroutines have now diverged into completely independent concepts. Funnily, this failure of definitions eventually comes to light when the programmer accidentally stumbles upon an asynchronous generator , which acts as both a generator and a coroutine at the same time 5 . Newer programming languages such as Kotlin (first appeared in 2011 ) and Go (first appeared in 2009 ) provide a dramatically better learning experience compared to Python (first appeared in 1990 ). Kotlin uses a much clearer definition of a coroutine and Go provides a goroutine as a first-class feature. Underhanded treatment of control flow and state \u00b6 Coroutines and generators are radical 6 control flow devices when viewed from the point of view of the now well-accepted structured programming paradigm. Both coroutines and generators retain their state while allowing the control to be transferred away from themselves. However, Python generators and Python (native) coroutines provide very different types of control flow. A Python generator provides a more definitive transfer of control compared to a Python (native) coroutine. This difference in control flow is a very important distinction between a Python generator and a Python (native) coroutine that is rarely mentioned, if at all 7 . Footnotes \u00b6 A regular computer program is synchronous, non-concurrent, single-threaded, and single-process. \u21a9 The use of (psuedo) random numbers without a known, pre-set random number seed can make the control paths appear random (or stochastic) to the programmer. As a result, the programmer may have to consider multiple control flow paths in order to properly reason about the program. We ignore this situation because (psuedo)randomness-induced control flow multiplicity is (1) easier to handle, and (2) orthogonal to async programming. \u21a9 Conway , Melvin E (1963). Design of a Separable Transition-diagram Compiler. Communications of the ACM. ACM. 6 (7): 396\u2013408. doi:10.1145/366663.366704 ( PDF ) \u21a9 This retroactive generalization is quite common in computer science where the specific implementation of a new concept arrives before the general concept. Once the specific implementation is found to be useful, it is generalized into an abstract concept. \u21a9 Author(s) of this course predict that the Python syntax will change once more to allow yield from within async def coroutine functions even though it isn't allowed as of PEP 492 . This is because (1) yield is allowed within an async def coroutine function in order to create an async generator , even though the previous PEP specifically forbade it, and (2) the refactoring concerns from PEP 380 still apply to async generators . This would formally complete the separation of generators and coroutines in Python. \u21a9 This is more philosophical than factual. The counter-point could also be argued, that, coroutines and generators need not be called radical because they are a form of structured concurrency , which is a a closely related concept to structured programming. \u21a9 It is much more common to find the following outdated distinction -- a Python generator only generates values but a Python coroutine can both generate and accept values. \u21a9","title":"Why is it difficult?"},{"location":"why-is-it-difficult/#sync-python-is-easy-but-async-python-is-not","text":"Tip Some terminology on this page may not make sense just yet. Feel free to skip and return. Synchronous Python programming is easy. So easy that it is often used as the first programming language and sometimes criticized for being too easy. But, learning asynchronous programming in Python is unreasonably difficult.","title":"Sync Python is easy but async Python is not"},{"location":"why-is-it-difficult/#async-programming-is-inherently-more-complicated","text":"A regular program 1 has a single 2 control flow path that a programmer can mentally walk through in order to reason about the program. An asynchronous program often has multiple, implicit control flow paths. A programmer has to think about all the possible paths in order to properly reason about the program. This makes asynchronous programming inherently more complicated than regular programming, no matter the choice of programming language.","title":"Async programming is inherently more complicated"},{"location":"why-is-it-difficult/#pythons-troubled-history","text":"Python arrived at async programming in incremental steps spread out over roughly two decades. Since the addition of simple generators in 2001, Python has constantly updated the semantics and syntax associated with async programming. 2001 Simple generators were proposed for Python 2.2 via PEP 255 . 2020 Generator-based coroutines were removed from Python 3.10. Teaching resources that were once up-to-date became stale over time. Python programmers had to unlearn the stale semantics and then learn the then-new semantics multiple times. Unfortunately, this historical cruft is reflected in the teaching materials. Async Python programming is very often taught in the same order as the order of incremental feature addition, starting with iterators , then generators , then generator-based coroutines , and finally, native coroutines . This style of teaching may be acceptable for a History Of Python lesson but it is unnecessarily disorienting for an otherwise python proficient programmer. A prime example of this historical cruft is the concept of generator-based coroutines which are scheduled for removal. Generator-based coroutines have been superseded by native coroutines . Teaching generator-based coroutines only serves to confuse the async beginner.","title":"Python's troubled history"},{"location":"why-is-it-difficult/#outdated-and-insufficient-terminology","text":"Async Python programming is taught using generators (aka semicoroutines ) and coroutines . The terms generators and coroutines are old. Generators Generators first appeared in 1975, were a prominent feature of the Icon programming language, and were the inspiration for Python's PEP 255 in 2001. Coroutines Coroutines were invented in 1958 and the first published explanation appeared in a 1963 paper by Melvin Conway 3 in context of the COBOL programming language and punch cards . Since their invention, coroutines have been implemented in many languages with the implementations differing from each other due to language-specific idiosyncrasies. As a result, the modern definition of a coroutine is a generalization 4 of all the different coroutine implementations. The general-purpose defintions of a generator and a coroutine are wholly insufficient when it comes to Python because they fail to properly distinguish between a Python generator and a Python (native) coroutine. Generators are considered a subset of coroutines and coroutines are considered an evolution of generators . While the preceding statement is historically correct, it is no longer applicable because Python generators and Python (native) coroutines have now diverged into completely independent concepts. Funnily, this failure of definitions eventually comes to light when the programmer accidentally stumbles upon an asynchronous generator , which acts as both a generator and a coroutine at the same time 5 . Newer programming languages such as Kotlin (first appeared in 2011 ) and Go (first appeared in 2009 ) provide a dramatically better learning experience compared to Python (first appeared in 1990 ). Kotlin uses a much clearer definition of a coroutine and Go provides a goroutine as a first-class feature.","title":"Outdated and insufficient terminology"},{"location":"why-is-it-difficult/#underhanded-treatment-of-control-flow-and-state","text":"Coroutines and generators are radical 6 control flow devices when viewed from the point of view of the now well-accepted structured programming paradigm. Both coroutines and generators retain their state while allowing the control to be transferred away from themselves. However, Python generators and Python (native) coroutines provide very different types of control flow. A Python generator provides a more definitive transfer of control compared to a Python (native) coroutine. This difference in control flow is a very important distinction between a Python generator and a Python (native) coroutine that is rarely mentioned, if at all 7 .","title":"Underhanded treatment of control flow and state"},{"location":"why-is-it-difficult/#footnotes","text":"A regular computer program is synchronous, non-concurrent, single-threaded, and single-process. \u21a9 The use of (psuedo) random numbers without a known, pre-set random number seed can make the control paths appear random (or stochastic) to the programmer. As a result, the programmer may have to consider multiple control flow paths in order to properly reason about the program. We ignore this situation because (psuedo)randomness-induced control flow multiplicity is (1) easier to handle, and (2) orthogonal to async programming. \u21a9 Conway , Melvin E (1963). Design of a Separable Transition-diagram Compiler. Communications of the ACM. ACM. 6 (7): 396\u2013408. doi:10.1145/366663.366704 ( PDF ) \u21a9 This retroactive generalization is quite common in computer science where the specific implementation of a new concept arrives before the general concept. Once the specific implementation is found to be useful, it is generalized into an abstract concept. \u21a9 Author(s) of this course predict that the Python syntax will change once more to allow yield from within async def coroutine functions even though it isn't allowed as of PEP 492 . This is because (1) yield is allowed within an async def coroutine function in order to create an async generator , even though the previous PEP specifically forbade it, and (2) the refactoring concerns from PEP 380 still apply to async generators . This would formally complete the separation of generators and coroutines in Python. \u21a9 This is more philosophical than factual. The counter-point could also be argued, that, coroutines and generators need not be called radical because they are a form of structured concurrency , which is a a closely related concept to structured programming. \u21a9 It is much more common to find the following outdated distinction -- a Python generator only generates values but a Python coroutine can both generate and accept values. \u21a9","title":"Footnotes"},{"location":"coroutines/eventloop/","text":"","title":"Event Loop"},{"location":"coroutines/introduction/","text":"Introduction \u00b6 Let's forget that we ever learned generators. Let's continue from the review of suspendables. Suspendable Type Python Implementation Definition Control Transfer Point Keywords Explicit Control Transfer Generators def yield , yield from Implicit Control Transfer Coroutines async def await Coroutines are completely independent from generators 1 . We need not even know about generators to learn about coroutines. Generators require the use of yield and yield from keywords. Coroutines require the use of async def and optionally the use of await keyword. Oddly enough, you can still use yield within a coroutine. This will create an object called asynchronous generator , which is both a generator and a coroutine hybrid generator. We will study the asynchronous generator in the advanced section (LINK ME) But, using yield from within a coroutine is illegal (CITE THE PEP). Definition \u00b6 A coroutine may be defined simply by adding a async before def . The following is an example of the simplest coroutine. The use of await keyword is not needed to define a coroutine. However, it is a SyntaxError to use await outside of an async def function. Python async def example_coroutine_function (): return 1 type ( example_coroutine_function ) # function The coroutine function example_coroutine_function is a suspendable and an extended function, analogous to a generator function. Calling example_coroutine_function does not execute the contents of the function. Instead, it returns a coroutine object. We need some other mechanism to execute the contents of example_coroutine_function . Python coro = example_coroutine_function () print ( coro ) # <coroutine object example_coroutine_function at 0x111b625c0> type ( coro ) # coroutine Coroutine does not implement the Iterator protocol \u00b6 For generators , we could use next , which is part of the Iterator protocol . Coroutine does not implement the Iterator protocol. Compare the following code with the corresponding code for a generator . Python from collections.abc import Iterator isinstance ( coro , Iterator ) # False coro . __iter__ # AttributeError: 'coroutine' object has no attribute '__iter__' coro . __next__ # AttributeError: 'coroutine' object has no attribute '__next__' next ( coro ) # TypeError: 'coroutine' object is not an iterator Automatic drive \u00b6 We cannot use next to drive coroutine objects. The coroutine equivalent to next is bit more complicated because imnplicit control transfer suspendables need an event loop. The event loop invisibly and implicitly transfers the control between coroutines. We have many choices for an event loop but we will use asyncio , which is the default event loop that comes with the python standard library. Python import asyncio output = asyncio . run ( example_coroutine_function ()) print ( output ) # 1 Manual drive \u00b6 We previously saw that for generators, next(generator_object) was equivalent to generator_object.send(None) . For coroutines, next doesn't work but send does. send method has the same semantics as with generators : send requires one argument coroutine needs to be primed before we can send a non- None value send(None) works but the value is received by await (we'll study await later ) Python example_coroutine_function () . send () # TypeError: coroutine.send() takes exactly one argument (0 given) example_coroutine_function () . send ( 'something' ) # TypeError: can't send non-None value to a just-started coroutine # There was no `await` in the coroutine function example_coroutine_function () . send ( None ) # StopIteration: 1 Custom drive \u00b6 Using a proper event loop such as the one provided by asyncio is the intended way to drive a coroutine. However, we could write our own little event loop to drive the coroutine ourselves. Python def drive ( coroutine_object ): while True : try : coroutine_object . send ( None ) except StopIteration as e : return e . value output = drive ( example_coroutine_function ()) print ( output ) # 1 There are two important things to note here: We used a while loop to make our event loop, just like we did in our pseudocode for the improved implementation of the plane ticket example. The .send method and StopIteration work for a coroutine object, just like they did for the generator object . Finally, our event loop is very rudimentary and will not work even with slightly more complicated toy examples. Confusing nomenclature \u00b6 Like the word generator , the word coroutine is ambiguous. Question Does coroutine refer to example_coroutine_function or example_coroutine_function() ? The answer is the same as that for generators . Object Type Name example_coroutine_function Coroutine function example_coroutine_function() Coroutine object It's best to use the word coroutine as an adjective instead of a noun. await is like yield \u00b6 Like yield , await is a control transfer point. You can suspend control at an await . await can also accept values. There is one difference \u2014 yield allowed us to yield any arbitrary value including nothing but await only allows us to await an Awaitable object. Fails Also Fails Works Python async def print_await_print (): print ( 'Starting execution' ) await 1 # Can't await an int because it's not an Awaitable print ( 'Ending execution' ) asyncio . run ( print_await_print ()) # ... # TypeError: object int can't be used in 'await' expression Python async def print_await_print (): print ( 'Starting execution' ) await # await needs something to await print ( 'Ending execution' ) # SyntaxError: invalid syntax Python import asyncio async def print_sleep_print (): print ( 'Starting execution' ) await asyncio . sleep ( 1 ) # This is a coroutine (which is an Awaitable) print ( 'Ending execution' ) asyncio . run ( print_sleep_print ()) # Starting execution # Ending execution Question What is an Awaitable object? Quite simply, an Awaitable object is an object with an __await__ method 2 . A coroutine is also an Awaitable object as you can see from the definition of a Coroutine . await is also a two-way street \u00b6 Fails Works Python import asyncio async def await_sleep (): print ( 'Starting execution' ) value1 = await asyncio . sleep ( 1 , result = 2 ) print ( value1 ) value2 = await asyncio . sleep ( 1 , result = 3 ) print ( value2 ) print ( 'Ending execution' ) # This will fail because `asyncio.sleep(1)` needs an event loop! await_sleep () . send ( None ) # RuntimeError: no running event loop Python async def no_await ( x ): return x * x async def await_no_await (): print ( 'Starting execution' ) value1 = await no_await ( 2 ) print ( value1 ) value2 = await no_await ( 3 ) print ( value2 ) print ( 'Ending execution' ) await_no_await () . send ( None ) From https://github.com/python/cpython/blob/d5d3249e8a37936d32266fa06ac20017307a1f70/Lib/_collections_abc.py#L57: Python ## coroutine ## async def _coro (): pass _coro = _coro () coroutine = type ( _coro ) Footnotes \u00b6 We are purposefully ignoring the existence of generator-based coroutines which are defunct as of Python 3.10. There is no benefit to learning generator-based coroutines except for unnecessary confusion. \u21a9 Yet again, we're ignoring the existence of defunct generator-based coroutines. This is a perfect example of how generator-based coroutines cause unnecessary confusion. Feel free to skip the rest of this footnote to avoid confusion or continue at your own risk . According to the official documentation on Awaitable , the defunct generator-based coroutines are considered awaitables even though they don't have an __await__ method. As a result, isinstance(gencoro, collections.abc.Awaitable) will return False ; use inspect.isawaitable() to properly detect generator-based coroutines as awaitables. \u21a9","title":"Introduction"},{"location":"coroutines/introduction/#introduction","text":"Let's forget that we ever learned generators. Let's continue from the review of suspendables. Suspendable Type Python Implementation Definition Control Transfer Point Keywords Explicit Control Transfer Generators def yield , yield from Implicit Control Transfer Coroutines async def await Coroutines are completely independent from generators 1 . We need not even know about generators to learn about coroutines. Generators require the use of yield and yield from keywords. Coroutines require the use of async def and optionally the use of await keyword. Oddly enough, you can still use yield within a coroutine. This will create an object called asynchronous generator , which is both a generator and a coroutine hybrid generator. We will study the asynchronous generator in the advanced section (LINK ME) But, using yield from within a coroutine is illegal (CITE THE PEP).","title":"Introduction"},{"location":"coroutines/introduction/#definition","text":"A coroutine may be defined simply by adding a async before def . The following is an example of the simplest coroutine. The use of await keyword is not needed to define a coroutine. However, it is a SyntaxError to use await outside of an async def function. Python async def example_coroutine_function (): return 1 type ( example_coroutine_function ) # function The coroutine function example_coroutine_function is a suspendable and an extended function, analogous to a generator function. Calling example_coroutine_function does not execute the contents of the function. Instead, it returns a coroutine object. We need some other mechanism to execute the contents of example_coroutine_function . Python coro = example_coroutine_function () print ( coro ) # <coroutine object example_coroutine_function at 0x111b625c0> type ( coro ) # coroutine","title":"Definition"},{"location":"coroutines/introduction/#coroutine-does-not-implement-the-iterator-protocol","text":"For generators , we could use next , which is part of the Iterator protocol . Coroutine does not implement the Iterator protocol. Compare the following code with the corresponding code for a generator . Python from collections.abc import Iterator isinstance ( coro , Iterator ) # False coro . __iter__ # AttributeError: 'coroutine' object has no attribute '__iter__' coro . __next__ # AttributeError: 'coroutine' object has no attribute '__next__' next ( coro ) # TypeError: 'coroutine' object is not an iterator","title":"Coroutine does not implement the Iterator protocol"},{"location":"coroutines/introduction/#automatic-drive","text":"We cannot use next to drive coroutine objects. The coroutine equivalent to next is bit more complicated because imnplicit control transfer suspendables need an event loop. The event loop invisibly and implicitly transfers the control between coroutines. We have many choices for an event loop but we will use asyncio , which is the default event loop that comes with the python standard library. Python import asyncio output = asyncio . run ( example_coroutine_function ()) print ( output ) # 1","title":"Automatic drive"},{"location":"coroutines/introduction/#manual-drive","text":"We previously saw that for generators, next(generator_object) was equivalent to generator_object.send(None) . For coroutines, next doesn't work but send does. send method has the same semantics as with generators : send requires one argument coroutine needs to be primed before we can send a non- None value send(None) works but the value is received by await (we'll study await later ) Python example_coroutine_function () . send () # TypeError: coroutine.send() takes exactly one argument (0 given) example_coroutine_function () . send ( 'something' ) # TypeError: can't send non-None value to a just-started coroutine # There was no `await` in the coroutine function example_coroutine_function () . send ( None ) # StopIteration: 1","title":"Manual drive"},{"location":"coroutines/introduction/#custom-drive","text":"Using a proper event loop such as the one provided by asyncio is the intended way to drive a coroutine. However, we could write our own little event loop to drive the coroutine ourselves. Python def drive ( coroutine_object ): while True : try : coroutine_object . send ( None ) except StopIteration as e : return e . value output = drive ( example_coroutine_function ()) print ( output ) # 1 There are two important things to note here: We used a while loop to make our event loop, just like we did in our pseudocode for the improved implementation of the plane ticket example. The .send method and StopIteration work for a coroutine object, just like they did for the generator object . Finally, our event loop is very rudimentary and will not work even with slightly more complicated toy examples.","title":"Custom drive"},{"location":"coroutines/introduction/#confusing-nomenclature","text":"Like the word generator , the word coroutine is ambiguous. Question Does coroutine refer to example_coroutine_function or example_coroutine_function() ? The answer is the same as that for generators . Object Type Name example_coroutine_function Coroutine function example_coroutine_function() Coroutine object It's best to use the word coroutine as an adjective instead of a noun.","title":"Confusing nomenclature"},{"location":"coroutines/introduction/#await-is-like-yield","text":"Like yield , await is a control transfer point. You can suspend control at an await . await can also accept values. There is one difference \u2014 yield allowed us to yield any arbitrary value including nothing but await only allows us to await an Awaitable object. Fails Also Fails Works Python async def print_await_print (): print ( 'Starting execution' ) await 1 # Can't await an int because it's not an Awaitable print ( 'Ending execution' ) asyncio . run ( print_await_print ()) # ... # TypeError: object int can't be used in 'await' expression Python async def print_await_print (): print ( 'Starting execution' ) await # await needs something to await print ( 'Ending execution' ) # SyntaxError: invalid syntax Python import asyncio async def print_sleep_print (): print ( 'Starting execution' ) await asyncio . sleep ( 1 ) # This is a coroutine (which is an Awaitable) print ( 'Ending execution' ) asyncio . run ( print_sleep_print ()) # Starting execution # Ending execution Question What is an Awaitable object? Quite simply, an Awaitable object is an object with an __await__ method 2 . A coroutine is also an Awaitable object as you can see from the definition of a Coroutine .","title":"await is like yield"},{"location":"coroutines/introduction/#await-is-also-a-two-way-street","text":"Fails Works Python import asyncio async def await_sleep (): print ( 'Starting execution' ) value1 = await asyncio . sleep ( 1 , result = 2 ) print ( value1 ) value2 = await asyncio . sleep ( 1 , result = 3 ) print ( value2 ) print ( 'Ending execution' ) # This will fail because `asyncio.sleep(1)` needs an event loop! await_sleep () . send ( None ) # RuntimeError: no running event loop Python async def no_await ( x ): return x * x async def await_no_await (): print ( 'Starting execution' ) value1 = await no_await ( 2 ) print ( value1 ) value2 = await no_await ( 3 ) print ( value2 ) print ( 'Ending execution' ) await_no_await () . send ( None ) From https://github.com/python/cpython/blob/d5d3249e8a37936d32266fa06ac20017307a1f70/Lib/_collections_abc.py#L57: Python ## coroutine ## async def _coro (): pass _coro = _coro () coroutine = type ( _coro )","title":"await is also a two-way street"},{"location":"coroutines/introduction/#footnotes","text":"We are purposefully ignoring the existence of generator-based coroutines which are defunct as of Python 3.10. There is no benefit to learning generator-based coroutines except for unnecessary confusion. \u21a9 Yet again, we're ignoring the existence of defunct generator-based coroutines. This is a perfect example of how generator-based coroutines cause unnecessary confusion. Feel free to skip the rest of this footnote to avoid confusion or continue at your own risk . According to the official documentation on Awaitable , the defunct generator-based coroutines are considered awaitables even though they don't have an __await__ method. As a result, isinstance(gencoro, collections.abc.Awaitable) will return False ; use inspect.isawaitable() to properly detect generator-based coroutines as awaitables. \u21a9","title":"Footnotes"},{"location":"generators/a-better-way-to-drive/","text":"A better way to drive \u00b6 Calling next repeatedly is tedious. There is a better way to drive a generator. But, first, let's look at next in detail. next is not that special \u00b6 It may appear that next is another special keyword like yield but it is not. As a quick test, try running this code yourself. Python # Remember to exit and restart the terminal after you redefine `next` # in order to avoid erroring out later examples. next = 1 print ( next ) # 1 yield = 2 # File \"<ipython-input-3-837215eb2b53>\", line 1 # yield = 2 # ^ # SyntaxError: invalid syntax next in not a keyword but a built-in function that is made available to you automatically when you start a python session. next is actually like len . Just like calling len on an object x simply calls x.__len__() , similarly, next(x) is nothing more than calling x.__next__() . This means that next is not specific to generators. You can call next on any class that has a __next__ method. Try the following code out yourself. Python class NextDemo : def __next__ ( self ): return 'You called next!' x = NextDemo () next ( x ) # 'You called next!' x . __next__ () # 'You called next!' __next__ is a part of Iterator protocol \u00b6 Iterator protocol requires the __next__ method to be implemented , along with the __iter__ method. You can define an Iterator independently of any generator or asynchronous programming concepts by simply defining the __next__ and __iter__ methods in a class. The following example shows such a class that can produce arbitrarily many squares of sequential natural numbers, on demand. All without using any generators or special keywords. Python class Squares : i = 1 def __iter__ ( self ): return self def __next__ ( self ): out = self . i * self . i self . i = self . i + 1 return out for square in Squares (): if square > 100 : break print ( square ) # 1 # 4 # 9 # 16 # 25 # 36 # 49 # 64 # 81 # 100 The benefit of an Iterator is that you can use it in a for loop without having to call next yourself, making for a terse syntax. Note that, in real-world code, you may want to inherit from collections.abc.Iterator . Also, while you could call next on NextDemo , you cannot run it in a for loop because it does not implement __iter__ . Generator implements Iterator protocol \u00b6 Generator implements the Iterator protocol as shown in the source . Generators are based on iterators but iterators are not based on generators. So, a generator is an iterator but an iterator may not necessarily be a generator. Python from collections.abc import Iterator def example_generator_function (): yield 1 gen = example_generator_function () isinstance ( gen , Iterator ) # True gen . __iter__ # <method-wrapper '__iter__' of generator object at 0x105e58190> gen . __next__ # <method-wrapper '__next__' of generator object at 0x105e58190> next ( gen ) # 1 Since generator is an iterator, we can drive a generator using a for loop instead of calling next ourselves. The following simple implementation of a range function demonstrates this. Python def my_simple_range ( start : int , stop : int ): i = start while i < stop : yield i i = i + 1 for i in my_simple_range ( 0 , 3 ): print ( i ) # 0 # 1 # 2 You can use a generator in list comprehensions exactly like you would use a materialised list or tuple . Python evens = [ i for i in my_simple_range ( 0 , 6 ) if i % 2 == 0 ] print ( evens ) # [0, 2, 4] You could also drive a generator to exhaustion/completion (if it is exhaustible) by simply calling list on it. Python three = list ( my_simple_range ( 0 , 3 )) print ( three ) # [0, 1, 2]","title":"A Better Way to Drive"},{"location":"generators/a-better-way-to-drive/#a-better-way-to-drive","text":"Calling next repeatedly is tedious. There is a better way to drive a generator. But, first, let's look at next in detail.","title":"A better way to drive"},{"location":"generators/a-better-way-to-drive/#next-is-not-that-special","text":"It may appear that next is another special keyword like yield but it is not. As a quick test, try running this code yourself. Python # Remember to exit and restart the terminal after you redefine `next` # in order to avoid erroring out later examples. next = 1 print ( next ) # 1 yield = 2 # File \"<ipython-input-3-837215eb2b53>\", line 1 # yield = 2 # ^ # SyntaxError: invalid syntax next in not a keyword but a built-in function that is made available to you automatically when you start a python session. next is actually like len . Just like calling len on an object x simply calls x.__len__() , similarly, next(x) is nothing more than calling x.__next__() . This means that next is not specific to generators. You can call next on any class that has a __next__ method. Try the following code out yourself. Python class NextDemo : def __next__ ( self ): return 'You called next!' x = NextDemo () next ( x ) # 'You called next!' x . __next__ () # 'You called next!'","title":"next is not that special"},{"location":"generators/a-better-way-to-drive/#__next__-is-a-part-of-iterator-protocol","text":"Iterator protocol requires the __next__ method to be implemented , along with the __iter__ method. You can define an Iterator independently of any generator or asynchronous programming concepts by simply defining the __next__ and __iter__ methods in a class. The following example shows such a class that can produce arbitrarily many squares of sequential natural numbers, on demand. All without using any generators or special keywords. Python class Squares : i = 1 def __iter__ ( self ): return self def __next__ ( self ): out = self . i * self . i self . i = self . i + 1 return out for square in Squares (): if square > 100 : break print ( square ) # 1 # 4 # 9 # 16 # 25 # 36 # 49 # 64 # 81 # 100 The benefit of an Iterator is that you can use it in a for loop without having to call next yourself, making for a terse syntax. Note that, in real-world code, you may want to inherit from collections.abc.Iterator . Also, while you could call next on NextDemo , you cannot run it in a for loop because it does not implement __iter__ .","title":"__next__ is a part of Iterator protocol"},{"location":"generators/a-better-way-to-drive/#generator-implements-iterator-protocol","text":"Generator implements the Iterator protocol as shown in the source . Generators are based on iterators but iterators are not based on generators. So, a generator is an iterator but an iterator may not necessarily be a generator. Python from collections.abc import Iterator def example_generator_function (): yield 1 gen = example_generator_function () isinstance ( gen , Iterator ) # True gen . __iter__ # <method-wrapper '__iter__' of generator object at 0x105e58190> gen . __next__ # <method-wrapper '__next__' of generator object at 0x105e58190> next ( gen ) # 1 Since generator is an iterator, we can drive a generator using a for loop instead of calling next ourselves. The following simple implementation of a range function demonstrates this. Python def my_simple_range ( start : int , stop : int ): i = start while i < stop : yield i i = i + 1 for i in my_simple_range ( 0 , 3 ): print ( i ) # 0 # 1 # 2 You can use a generator in list comprehensions exactly like you would use a materialised list or tuple . Python evens = [ i for i in my_simple_range ( 0 , 6 ) if i % 2 == 0 ] print ( evens ) # [0, 2, 4] You could also drive a generator to exhaustion/completion (if it is exhaustible) by simply calling list on it. Python three = list ( my_simple_range ( 0 , 3 )) print ( three ) # [0, 1, 2]","title":"Generator implements Iterator protocol"},{"location":"generators/examples/","text":"Examples \u00b6 We discuss some more real-world examples here. Examples may be added or removed from this section later. range \u00b6 A generator is the perfect tool to write a range function. range is often used only to index or iterate over a list-like object. Even though range is in-built, we will rewrite a simpler version of range ourselves to see how generators are perfectly suited for this task. Naive Approach \u00b6 Let's first consider a naive, non-generator, simple function. Python def naive_range ( start , stop ): out = [] i = start while i < stop : out . append ( i ) i = i + 1 return out print ( naive_range ( 0 , 10 )) # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] # This may take a while and may run out of memory naive_range ( 0 , 10000000 ) for i in naive_range ( 0 , 10000000 ): # use i to index into another list-like object The simple function naive_range materializes the entire range into a list and returns it. This takes a lot of memory. Imagine you want to iterate over a 10M long list-like object. Using naive_range to iterate over it would first create another 10M long list in memory. This is a waste of memory because you only want one value of the iteration index i in memory at a time. Generator approach \u00b6 We already saw a generator-based range-like function but let's see it again. Python def generator_range ( start , stop ): i = start while i < stop : yield i i = i + 1 print ( list ( generator_range ( 0 , 10 ))) # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] # This does not take a lot of memory and # returns a generator object immediately. generator_range ( 0 , 10000000 ) for i in generator_range ( 0 , 10000000 ): # use i to index into another list-like object You should try it out yourself to see the difference. Since generators follow the iterator protocol, we don't need any special syntax when using generator_range in a for loop. range in Python 2 and 3 The range function in Python 2 used lists much like our naive_range while the range function in Python 3 uses iterators much like our generator_range . See this . Unbounded range \u00b6 Generator-based approach allows us to generate integers unboundedly. interestingly, this is even simpler than our generator_range above. This was clearly not possible if we use a naive list-based approach. Python def unbounded_range ( start ): i = start while True : yield i i = i + 1 r = unbounded_range ( 0 ) next ( r ) # 0 next ( r ) # 1 next ( r ) # 2 # Use in a for loop with care to avoid # an infinitely running loop. for i in unbounded_range ( 0 ): # do something with i print ( i ) if i > 10 : break # 0 # ... # 11 Random number generator \u00b6 Another surprising perfect fit for generators is a random number generator. Random number generators are typically state machines. Python def discrete_uniform_lgc ( seed = 894965 , modulus = 2 ** 32 , coeff = 1664525 , constant = 1013904223 ): x = seed while True : x = ( coeff * x + constant ) % modulus yield x FILL ME","title":"Examples"},{"location":"generators/examples/#examples","text":"We discuss some more real-world examples here. Examples may be added or removed from this section later.","title":"Examples"},{"location":"generators/examples/#range","text":"A generator is the perfect tool to write a range function. range is often used only to index or iterate over a list-like object. Even though range is in-built, we will rewrite a simpler version of range ourselves to see how generators are perfectly suited for this task.","title":"range"},{"location":"generators/examples/#naive-approach","text":"Let's first consider a naive, non-generator, simple function. Python def naive_range ( start , stop ): out = [] i = start while i < stop : out . append ( i ) i = i + 1 return out print ( naive_range ( 0 , 10 )) # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] # This may take a while and may run out of memory naive_range ( 0 , 10000000 ) for i in naive_range ( 0 , 10000000 ): # use i to index into another list-like object The simple function naive_range materializes the entire range into a list and returns it. This takes a lot of memory. Imagine you want to iterate over a 10M long list-like object. Using naive_range to iterate over it would first create another 10M long list in memory. This is a waste of memory because you only want one value of the iteration index i in memory at a time.","title":"Naive Approach"},{"location":"generators/examples/#generator-approach","text":"We already saw a generator-based range-like function but let's see it again. Python def generator_range ( start , stop ): i = start while i < stop : yield i i = i + 1 print ( list ( generator_range ( 0 , 10 ))) # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] # This does not take a lot of memory and # returns a generator object immediately. generator_range ( 0 , 10000000 ) for i in generator_range ( 0 , 10000000 ): # use i to index into another list-like object You should try it out yourself to see the difference. Since generators follow the iterator protocol, we don't need any special syntax when using generator_range in a for loop. range in Python 2 and 3 The range function in Python 2 used lists much like our naive_range while the range function in Python 3 uses iterators much like our generator_range . See this .","title":"Generator approach"},{"location":"generators/examples/#unbounded-range","text":"Generator-based approach allows us to generate integers unboundedly. interestingly, this is even simpler than our generator_range above. This was clearly not possible if we use a naive list-based approach. Python def unbounded_range ( start ): i = start while True : yield i i = i + 1 r = unbounded_range ( 0 ) next ( r ) # 0 next ( r ) # 1 next ( r ) # 2 # Use in a for loop with care to avoid # an infinitely running loop. for i in unbounded_range ( 0 ): # do something with i print ( i ) if i > 10 : break # 0 # ... # 11","title":"Unbounded range"},{"location":"generators/examples/#random-number-generator","text":"Another surprising perfect fit for generators is a random number generator. Random number generators are typically state machines. Python def discrete_uniform_lgc ( seed = 894965 , modulus = 2 ** 32 , coeff = 1664525 , constant = 1013904223 ): x = seed while True : x = ( coeff * x + constant ) % modulus yield x FILL ME","title":"Random number generator"},{"location":"generators/generator-class/","text":"Generator Class \u00b6 We saw that calling a generator function returns a generator object. Question If there is a generator object then where is the corresponding generator class? 1 We also saw that next is not that special and driving a generator does not require the special keyword yield . Question Shouldn't we be able to define our own generator class without having to depend on yield or a generator function? Minimal example from scratch \u00b6 Such curiosity would help us demystify the implementation of generators. Let's try to write a minimal class, from scratch, to replace the generator function my_simple_range . Generator Class Generator Function Python class MySimpleRangeMinimal : def __init__ ( self , start : int , stop : int ): self . start = start self . stop = stop self . i = self . start def send ( self , value ): if self . i < self . stop : out = self . i self . i = self . i + 1 return out raise StopIteration def __next__ ( self ): return self . send ( None ) def __iter__ ( self ): return self print ( list ( MySimpleRangeMinimal ( 0 , 6 ))) # [0, 1, 2, 3, 4, 5] Python def my_simple_range ( start : int , stop : int ): i = start while i < stop : yield i i = i + 1 print ( list ( my_simple_range ( 0 , 6 ))) # [0, 1, 2, 3, 4, 5] The class MySimpleRangeMinimal performs the same basic task as the generator function my_simple_range without needing to use yield or any fancy concepts such as simple or extended functions and explicit or implicit control transfer suspendables. Not only that, calling the generator function using my_simple_range(0, 6) is eerily similar to calling the constructor of the class in MySimpleRangeMinimal(0, 6) . We hinted at this earlier in the course. The class MySimpleRangeMinimal does not have any dependency but it also has a few drawbacks. Firstly, it does not implement throw and close , which are the other methods required to a generator. Secondly, it appears to have boilerplate code in __next__ and __iter__ if we compare it to the source . Thirdly, it's not a generator even if it can perform the same basic task as a generator. You can see it yourself as shown below. Python print ( type ( my_simple_range ( 0 , 6 ))) # <class 'generator'> print ( type ( MySimpleRangeMinimal ( 0 , 6 ))) # <class '__main__.MySimpleRangeMinimal'> from collections.abc import Generator issubclass ( MySimpleRangeMinimal , Generator ) # False Improved example using ABC \u00b6 We can improve upon all of the shortcomings by simply inheriting from collections.abc.Generator . It helps to look at the source for Generator, as we're writing the following code. Python from collections.abc import Generator class MySimpleRange ( Generator ): def __init__ ( self , start : int , stop : int ): self . start = start self . stop = stop self . i = self . start def send ( self , value ): if self . i < self . stop : out = self . i self . i = self . i + 1 return out raise StopIteration def throw ( self , typ , val = None , tb = None ): super () . throw ( typ , val , tb ) print ( list ( MySimpleRange ( 0 , 6 ))) # [0, 1, 2, 3, 4, 5] print ( type ( MySimpleRange ( 0 , 6 ))) # <class '__main__.MySimpleRange'> issubclass ( MySimpleRange , Generator ) # True The constructor and the send method are the same for both MySimpleRangeMinimal and MySimpleRange . But, we did not need to write __next__ and __iter__ boilerplate methods for MySimpleRange at the expense of writing throw , which simply calls the method from the super class. Since we inherited from Generator , it is expected that MySimpleRange be a subclass of Generator . It may be interesting to note that my_simple_range(0, 6) returns a generator -type object. The type generator is an built-in type. Neither MySimpleRangeMinimal(0, 6) nor MySimpleRange(0, 6) are objects of any built-in type. More importantly, MySimpleRange provides the close and throw methods which MySimpleRangeMinimal did not. If you chose to write a generator class (instead of a generator function) in the real world, then inheriting from Generator is the better way. Python x = MySimpleRange ( 0 , 6 ) next ( x ) # 0 x . close () y = MySimpleRangeMinimal ( 0 , 6 ) next ( y ) # 0 y . close () Running cost vs fixed cost \u00b6 Notice how much more verbose and complicated MySimpleRange is compared to my_simple_range . For the generator class, we needed to inherit from Generator , write a constructor method, write a send method that raises StopIteration , write a throw method even if all it does is call its super, and then link all of these things together into a working class. For the generator function, we were able to avoid all of these chores in lieu of the one-time expense of having to define and learn about suspendable functions. Some would argue that the reduced running cost of writing generator functions is worth the higher, cognitive, initial fixed cost of learning suspendable functions. Footnotes \u00b6 Quick answer: if a generator object is created by calling a generator function, then the corresponding class is only implicitly defined. \u21a9","title":"Generator Class"},{"location":"generators/generator-class/#generator-class","text":"We saw that calling a generator function returns a generator object. Question If there is a generator object then where is the corresponding generator class? 1 We also saw that next is not that special and driving a generator does not require the special keyword yield . Question Shouldn't we be able to define our own generator class without having to depend on yield or a generator function?","title":"Generator Class"},{"location":"generators/generator-class/#minimal-example-from-scratch","text":"Such curiosity would help us demystify the implementation of generators. Let's try to write a minimal class, from scratch, to replace the generator function my_simple_range . Generator Class Generator Function Python class MySimpleRangeMinimal : def __init__ ( self , start : int , stop : int ): self . start = start self . stop = stop self . i = self . start def send ( self , value ): if self . i < self . stop : out = self . i self . i = self . i + 1 return out raise StopIteration def __next__ ( self ): return self . send ( None ) def __iter__ ( self ): return self print ( list ( MySimpleRangeMinimal ( 0 , 6 ))) # [0, 1, 2, 3, 4, 5] Python def my_simple_range ( start : int , stop : int ): i = start while i < stop : yield i i = i + 1 print ( list ( my_simple_range ( 0 , 6 ))) # [0, 1, 2, 3, 4, 5] The class MySimpleRangeMinimal performs the same basic task as the generator function my_simple_range without needing to use yield or any fancy concepts such as simple or extended functions and explicit or implicit control transfer suspendables. Not only that, calling the generator function using my_simple_range(0, 6) is eerily similar to calling the constructor of the class in MySimpleRangeMinimal(0, 6) . We hinted at this earlier in the course. The class MySimpleRangeMinimal does not have any dependency but it also has a few drawbacks. Firstly, it does not implement throw and close , which are the other methods required to a generator. Secondly, it appears to have boilerplate code in __next__ and __iter__ if we compare it to the source . Thirdly, it's not a generator even if it can perform the same basic task as a generator. You can see it yourself as shown below. Python print ( type ( my_simple_range ( 0 , 6 ))) # <class 'generator'> print ( type ( MySimpleRangeMinimal ( 0 , 6 ))) # <class '__main__.MySimpleRangeMinimal'> from collections.abc import Generator issubclass ( MySimpleRangeMinimal , Generator ) # False","title":"Minimal example from scratch"},{"location":"generators/generator-class/#improved-example-using-abc","text":"We can improve upon all of the shortcomings by simply inheriting from collections.abc.Generator . It helps to look at the source for Generator, as we're writing the following code. Python from collections.abc import Generator class MySimpleRange ( Generator ): def __init__ ( self , start : int , stop : int ): self . start = start self . stop = stop self . i = self . start def send ( self , value ): if self . i < self . stop : out = self . i self . i = self . i + 1 return out raise StopIteration def throw ( self , typ , val = None , tb = None ): super () . throw ( typ , val , tb ) print ( list ( MySimpleRange ( 0 , 6 ))) # [0, 1, 2, 3, 4, 5] print ( type ( MySimpleRange ( 0 , 6 ))) # <class '__main__.MySimpleRange'> issubclass ( MySimpleRange , Generator ) # True The constructor and the send method are the same for both MySimpleRangeMinimal and MySimpleRange . But, we did not need to write __next__ and __iter__ boilerplate methods for MySimpleRange at the expense of writing throw , which simply calls the method from the super class. Since we inherited from Generator , it is expected that MySimpleRange be a subclass of Generator . It may be interesting to note that my_simple_range(0, 6) returns a generator -type object. The type generator is an built-in type. Neither MySimpleRangeMinimal(0, 6) nor MySimpleRange(0, 6) are objects of any built-in type. More importantly, MySimpleRange provides the close and throw methods which MySimpleRangeMinimal did not. If you chose to write a generator class (instead of a generator function) in the real world, then inheriting from Generator is the better way. Python x = MySimpleRange ( 0 , 6 ) next ( x ) # 0 x . close () y = MySimpleRangeMinimal ( 0 , 6 ) next ( y ) # 0 y . close ()","title":"Improved example using ABC"},{"location":"generators/generator-class/#running-cost-vs-fixed-cost","text":"Notice how much more verbose and complicated MySimpleRange is compared to my_simple_range . For the generator class, we needed to inherit from Generator , write a constructor method, write a send method that raises StopIteration , write a throw method even if all it does is call its super, and then link all of these things together into a working class. For the generator function, we were able to avoid all of these chores in lieu of the one-time expense of having to define and learn about suspendable functions. Some would argue that the reduced running cost of writing generator functions is worth the higher, cognitive, initial fixed cost of learning suspendable functions.","title":"Running cost vs fixed cost"},{"location":"generators/generator-class/#footnotes","text":"Quick answer: if a generator object is created by calling a generator function, then the corresponding class is only implicitly defined. \u21a9","title":"Footnotes"},{"location":"generators/history/","text":"History \u00b6 This section may be omitted without any loss of continuity. This section is only for python history buffs and may actually increase confusion than improve clarity. TBD","title":"History"},{"location":"generators/history/#history","text":"This section may be omitted without any loss of continuity. This section is only for python history buffs and may actually increase confusion than improve clarity. TBD","title":"History"},{"location":"generators/introduction/","text":"Introduction \u00b6 Definition \u00b6 A generator may be defined simply by including a syntactically reachable yield (or yield from ) keyword within a function. The following is an example of the simplest generator. Python def example_generator_function (): yield 1 Notice how we used the word function to describe the above example. This is because example_generator_function is indeed a function. You can call it by executing example_generator_function() like any other python function, as shown below. Python example_generator_function () However, example_generator_function is not a simple function. This means that calling it will not execute the contents of the function. Feel free to check this out yourself. Python x = example_generator_function () print ( x ) # <generator object example_generator_function at 0x10be77740> The result of calling example_generator_function is stored in x and it is not 1 , or None , or anything you would've expected had it been a simple function. Instead, calling example_generator_function returns a generator object. example_generator_function is a suspendable and therefore an extended function. This means that we require some other mechanism to execute the contents of example_generator_function . One such mechanism is to call next on the generator object x . Python next ( x ) # 1 Later on, we will look at next in detail and discuss other ways of executing the contents of a generator function. Confusing nomenclature \u00b6 The word generator can be ambiguous. Does it refer to example_generator_function or x ? Ideally, a function like example_generator_function would always be called a generator function , an object like x would always be called a generator object , and the word generator would always be used as an adjective instead of a noun. Sadly, such carefulness in word choice is uncommon and the word generator is often used to refer to both a generator function and a generator object. yield is like return \u00b6 yield may be thought of as a free-spirited cousin of return . Both yield and return optionally return a value back to the caller of the function they are in. yield suspends the execution of the rest of the function leaving the possibility open for a resumption of execution. In contrast, return ends the execution of the rest of the function without any chance of resumption. This is best demonstrated by the following pair of functions. Simple Function Generator (Extended Function) Python def print_return_and_print (): print ( \"Starting execution\" ) return 1 print ( \"Ending execution\" ) y = print_return_and_print () # Starting execution print ( y ) # 1 next ( y ) # --------------------------------------------------------------------------- # TypeError Traceback (most recent call last) # <ipython-input-42-cf9ac561a401> in <module> # ----> 1 next(y) # # TypeError: 'int' object is not an iterator Python def print_yield_and_print (): print ( \"Starting execution\" ) yield 1 print ( \"Ending execution\" ) z = print_yield_and_print () print ( z ) # <generator object print_yield_and_print at 0x10bfb0510> z_value = next ( z ) # Starting execution print ( z_value ) # 1 next ( z ) # Ending execution # --------------------------------------------------------------------------- # StopIteration Traceback (most recent call last) # <ipython-input-38-81b9d2f0f16a> in <module> # ----> 1 next(z) # # StopIteration: While the functions print_return_and_print and print_yield_and_print look very similar, they are structurally very different. print_return_and_print is a simple function and print_yield_and_print is an extended function. When we call print_return_and_print , we see that Starting execution is printed out and the value 1 is stored in y . The string Ending execution is never printed out with no recourse besides changing the function itself 1 . Finally, calling next on y gives us a TypeError error because y is just 1 and next cannot be called on 1 . In contrast, when we call print_yield_and_print , nothing gets printed at all and the value 1 is not stored in z . Instead, z is a generator object. When we call next on z , the contents of print_yield_and_print are executed until the yield (or suspension) point, Starting execution is printed, and the value 1 is stored in z_value . At this point, the execution of the contents of print_yield_and_print is suspended and the control is transferred back to the caller. The execution may be resumed by calling next again on the same generator object z from immediately before. Calling a second next resumes the execution from where it was suspended 2 , prints out Ending execution , and then throws a StopIteration error, which, as we will discuss later, is expected and does not mean that there is a mistake in our code. Brevity has its costs \u00b6 Unprimed readers may underestimate how much of a structural difference a tiny change like replacing return with yield can create. Imagine that you've written a complicated generator function and accompanying downstream code that executes the contents of the said generator function. One day, you decide to refactor the generator function and comment out all the yield statements, which reduces the extended function to a simple function. As a result of this edit, the downstream code that was previously able to drive the generator now throws an error, similar to the TypeError we got when we called next on y . All downstream code that interacts with this function now needs to be rewritten. On some other day, if you decide to revisit the function and uncomment any of the yield statements, you will need to update the downstream code again, this time in reverse. Summary Even though they look alike, a simple function and a generator function are not interchangeable. As a side note, newer languages may have a less cumbersome design. One example is a goroutine in Go. Go allows you to re-use the same function in two ways, once, as a simple function that you call directly and execute, and second, asynchronously in a goroutine. You don't need to write two variants of the same idea. You can write once and decide whether you want to call it synchronously or asynchronously later. yield is a two way street \u00b6 Perhaps, as an act of rebellion, yield can accept a value from the caller into the generator function. This is best experienced in action. Python def receive_value (): value = yield 1 print ( 'received value = {} ' . format ( value )) yield 2 gen = receive_value () print ( gen ) # <generator object receive_value at 0x11106e6d0> first = next ( gen ) print ( first ) # 1 second = gen . send ( 'hello' ) # received value = hello print ( second ) # 2 This time, our generator function receive_value has two yield expressions and the first yield expression expects to receive a value. As usual, we can start to drive the generator by calling next on the generator object gen . Once the execution is suspended after the first next call, we call the send method of the generator object. This allows us to send any value, such as 'hello' in our case, back to the generator function. The send method runs from the first yield expression until the second yield statement, which is why send returns the value 2 , which is then stored in second . Behold the power \u00b6 A generator is a very powerful construct because it is able to both return and receive values, multiple times, without losing its state. A generator is bestowed with all the benefits of a function, which means that a generator function can accept function arguments, maintain its own independent scope, and contain arbitrarily complicated code. For example, we could return multiple values from a generator function at different times. Or, we could choose which branch of an if-else statement gets executed inside a live, running generator based on the value it receives. Such tremendous freedom is not granted to a mere simple function. In some ways, as we will see next, a generator is a somewhat complicated class unto itself. Many readers may have more questions about the mechanics of yield such as how many yield statements can we have, can a function have both yield and return statements, and what is meant by syntactically reachable. We discuss such questions in the Mechanics by Examples section after we have studied the underlying design of generators. Footnotes \u00b6 Calling print_return_and_print a second time would repeat the same behavior and will still not print out Ending execution . \u21a9 There are other ways besides next to resume a suspended execution. \u21a9","title":"Introduction"},{"location":"generators/introduction/#introduction","text":"","title":"Introduction"},{"location":"generators/introduction/#definition","text":"A generator may be defined simply by including a syntactically reachable yield (or yield from ) keyword within a function. The following is an example of the simplest generator. Python def example_generator_function (): yield 1 Notice how we used the word function to describe the above example. This is because example_generator_function is indeed a function. You can call it by executing example_generator_function() like any other python function, as shown below. Python example_generator_function () However, example_generator_function is not a simple function. This means that calling it will not execute the contents of the function. Feel free to check this out yourself. Python x = example_generator_function () print ( x ) # <generator object example_generator_function at 0x10be77740> The result of calling example_generator_function is stored in x and it is not 1 , or None , or anything you would've expected had it been a simple function. Instead, calling example_generator_function returns a generator object. example_generator_function is a suspendable and therefore an extended function. This means that we require some other mechanism to execute the contents of example_generator_function . One such mechanism is to call next on the generator object x . Python next ( x ) # 1 Later on, we will look at next in detail and discuss other ways of executing the contents of a generator function.","title":"Definition"},{"location":"generators/introduction/#confusing-nomenclature","text":"The word generator can be ambiguous. Does it refer to example_generator_function or x ? Ideally, a function like example_generator_function would always be called a generator function , an object like x would always be called a generator object , and the word generator would always be used as an adjective instead of a noun. Sadly, such carefulness in word choice is uncommon and the word generator is often used to refer to both a generator function and a generator object.","title":"Confusing nomenclature"},{"location":"generators/introduction/#yield-is-like-return","text":"yield may be thought of as a free-spirited cousin of return . Both yield and return optionally return a value back to the caller of the function they are in. yield suspends the execution of the rest of the function leaving the possibility open for a resumption of execution. In contrast, return ends the execution of the rest of the function without any chance of resumption. This is best demonstrated by the following pair of functions. Simple Function Generator (Extended Function) Python def print_return_and_print (): print ( \"Starting execution\" ) return 1 print ( \"Ending execution\" ) y = print_return_and_print () # Starting execution print ( y ) # 1 next ( y ) # --------------------------------------------------------------------------- # TypeError Traceback (most recent call last) # <ipython-input-42-cf9ac561a401> in <module> # ----> 1 next(y) # # TypeError: 'int' object is not an iterator Python def print_yield_and_print (): print ( \"Starting execution\" ) yield 1 print ( \"Ending execution\" ) z = print_yield_and_print () print ( z ) # <generator object print_yield_and_print at 0x10bfb0510> z_value = next ( z ) # Starting execution print ( z_value ) # 1 next ( z ) # Ending execution # --------------------------------------------------------------------------- # StopIteration Traceback (most recent call last) # <ipython-input-38-81b9d2f0f16a> in <module> # ----> 1 next(z) # # StopIteration: While the functions print_return_and_print and print_yield_and_print look very similar, they are structurally very different. print_return_and_print is a simple function and print_yield_and_print is an extended function. When we call print_return_and_print , we see that Starting execution is printed out and the value 1 is stored in y . The string Ending execution is never printed out with no recourse besides changing the function itself 1 . Finally, calling next on y gives us a TypeError error because y is just 1 and next cannot be called on 1 . In contrast, when we call print_yield_and_print , nothing gets printed at all and the value 1 is not stored in z . Instead, z is a generator object. When we call next on z , the contents of print_yield_and_print are executed until the yield (or suspension) point, Starting execution is printed, and the value 1 is stored in z_value . At this point, the execution of the contents of print_yield_and_print is suspended and the control is transferred back to the caller. The execution may be resumed by calling next again on the same generator object z from immediately before. Calling a second next resumes the execution from where it was suspended 2 , prints out Ending execution , and then throws a StopIteration error, which, as we will discuss later, is expected and does not mean that there is a mistake in our code.","title":"yield is like return"},{"location":"generators/introduction/#brevity-has-its-costs","text":"Unprimed readers may underestimate how much of a structural difference a tiny change like replacing return with yield can create. Imagine that you've written a complicated generator function and accompanying downstream code that executes the contents of the said generator function. One day, you decide to refactor the generator function and comment out all the yield statements, which reduces the extended function to a simple function. As a result of this edit, the downstream code that was previously able to drive the generator now throws an error, similar to the TypeError we got when we called next on y . All downstream code that interacts with this function now needs to be rewritten. On some other day, if you decide to revisit the function and uncomment any of the yield statements, you will need to update the downstream code again, this time in reverse. Summary Even though they look alike, a simple function and a generator function are not interchangeable. As a side note, newer languages may have a less cumbersome design. One example is a goroutine in Go. Go allows you to re-use the same function in two ways, once, as a simple function that you call directly and execute, and second, asynchronously in a goroutine. You don't need to write two variants of the same idea. You can write once and decide whether you want to call it synchronously or asynchronously later.","title":"Brevity has its costs"},{"location":"generators/introduction/#yield-is-a-two-way-street","text":"Perhaps, as an act of rebellion, yield can accept a value from the caller into the generator function. This is best experienced in action. Python def receive_value (): value = yield 1 print ( 'received value = {} ' . format ( value )) yield 2 gen = receive_value () print ( gen ) # <generator object receive_value at 0x11106e6d0> first = next ( gen ) print ( first ) # 1 second = gen . send ( 'hello' ) # received value = hello print ( second ) # 2 This time, our generator function receive_value has two yield expressions and the first yield expression expects to receive a value. As usual, we can start to drive the generator by calling next on the generator object gen . Once the execution is suspended after the first next call, we call the send method of the generator object. This allows us to send any value, such as 'hello' in our case, back to the generator function. The send method runs from the first yield expression until the second yield statement, which is why send returns the value 2 , which is then stored in second .","title":"yield is a two way street"},{"location":"generators/introduction/#behold-the-power","text":"A generator is a very powerful construct because it is able to both return and receive values, multiple times, without losing its state. A generator is bestowed with all the benefits of a function, which means that a generator function can accept function arguments, maintain its own independent scope, and contain arbitrarily complicated code. For example, we could return multiple values from a generator function at different times. Or, we could choose which branch of an if-else statement gets executed inside a live, running generator based on the value it receives. Such tremendous freedom is not granted to a mere simple function. In some ways, as we will see next, a generator is a somewhat complicated class unto itself. Many readers may have more questions about the mechanics of yield such as how many yield statements can we have, can a function have both yield and return statements, and what is meant by syntactically reachable. We discuss such questions in the Mechanics by Examples section after we have studied the underlying design of generators.","title":"Behold the power"},{"location":"generators/introduction/#footnotes","text":"Calling print_return_and_print a second time would repeat the same behavior and will still not print out Ending execution . \u21a9 There are other ways besides next to resume a suspended execution. \u21a9","title":"Footnotes"},{"location":"generators/mechanics-by-examples/","text":"Mechanics by Examples \u00b6 Curious readers may have lots of questions on how exactly yield behaves. Let's answer them with examples. yield under an impossible branch \u00b6 In Introduction , we said that a syntactically reachable yield within a function makes it a generator function. The important word is syntactically . So, even if a yield statement is inside a never-to-be-executed if branch, such as shown below, the function would still be a generator function. Python def still_a_generator_function (): print ( 'Entering' ) if False : yield 1 print ( 'Exiting' ) x = still_a_generator_function () print ( type ( x )) # <class 'generator'> next ( x ) # Entering # Exiting # --------------------------------------------------------------------------- # StopIteration Traceback (most recent call last) # <ipython-input-4-92de4e9f6b1e> in <module> # ----> 1 next(x) # StopIteration: The above generator function is indeed quite strange. The yield statment will never get to execute because it is under an impossible if branch, and yet, presence of the yield keyword makes for a generator function. Then, when, we call next on the generator function, it does not find even a single yield statement (where the execution could've been suspended), reaches the end of the function, and throws a StopIteration 1 . Allowing an impossible to reach yield to create a generator is still a reasonable decision. This is because in a more real-world example, the python interpreter can never know which way an if statement would resolve. Consider the following snippet. Python def real_world_function (): # ... if some_variable . some_method (): yield something else : # Do anything but yield There is no way of knowing whether some_variable.some_method() would be considered equivalent to True or not. What if some_variable.some_method() uses pseudo random numbers and can return a True -equivalent 2 during some runs and a False -equivalent during some other runs? Even if some_variable.some_method() does not use random numbers, code changes in this method would affect which branch of if-else is executed inside real_world_function . Programmers would also face the same exact problem as the interpreter. How would you write the downstream code to execute the contents of real_world_function ? We've already seen that we require very different code to drive a generator function versus running a simple function. The same applies to other control flow constructs such as while and do while or even something as evil as this. Python def evil_generator_function (): while True : pass yield 1 This behavior can also be used to your advantage when you're editing code. Suppose that you have a generator function called frequently_edited_gen_fun . You've written downstream code to use frequently_edited_gen_fun as a generator function. Now, you need to edit it and as a result of this edit, you have to remove all the yield statements. Removing all yield statements would reduce frequently_edited_gen_fun to a simple function causing all the downstream code to fail unless rewritten. You can salvage the situation by adding an impossible to reach yield like the one shown in one of the examples above. This yield would never be reached but it will still prevent frequently_edited_gen_fun from becoming a simple function. MENTION THAT REJECTED PIP HERE (COFUNCTIONS, WAS IT?). See yet another example in return before a yield . Must we return something with yield ? \u00b6 No. We can yield without specifying a yield value. Python def no_yield_value (): print ( 'Entering' ) yield print ( 'Exiting' ) y = no_yield_value () y_yield_value = next ( y ) # Entering print ( y_yield_value ) # None If we don't specify a yield value, None is yielded. This is similar to return in the following simple function. Python def no_return_value (): return no_return_value () is None # True yield is an expression \u00b6 Since PEP 342 , yield is an expression rather than a statement, even if it can be used in a statement form. Python def yield_is_an_expression (): product_value = ( yield 1 ) * ( yield 2 ) # expression form yield 3 # statement form The above code is legal syntax. You should try this out yourself because things will become murky in a moment. We've already seen that we can send value into a a generator via the yield keyword. The above generator function seems to compute product_value as a sum of two yield expressions. Only difference is that this time the expressions are wrapped in parentheses. This is also important. Thw following statements list the rules of engagement when it comes to yield . yield is always an expression, even if it can be written in a statement form (like a return statement) yield expressions almost always require parentheses with two known exceptions. Overuse of parentheses is encouraged. Every yield expression has a value, even if the value is None . Let's look at an example that is easier to run than the one above. We'll discuss why this example is easier than the one above in a moment. Python def fill_list_using_yields (): list_value = [( yield ), ( yield )] print ( 'list_value= {} ' . format ( str ( list_value ))) yield Drive using next \u00b6 We can drive the above generator in at least two ways, one is using next and the other using send . Let's see next first. Python z = fill_list_using_yields () z_value_1 = next ( z ) z_value_2 = next ( z ) z_value_3 = next ( z ) # list_value=[None, None] In the above snippet, we didn't explicitly send any value to the generator and it appears that the generator assumed that we sent back None s. There is an important but simple reason for this. Calling the next function calls the __next__ method. If this __next__ is the default method (which is indeed the case for fill_list_using_yields ), then __next__ simply calls the send method with a None argument. Thus, calling next(z) is equivalent to calling z.__next__() , which is equivalent to calling z.send(None) . This clarifies why list_value contains None s. If we were to redefine __next__ , perhaps by defining a generator class, then the outcome could've been different. Drive using send \u00b6 Let's look at send now. When we use the send method, we explicitly send back a value to the generator. Expectedly, trying to call send without any argument fails. Python fill_list_using_yields () . send () # TypeError: send() takes exactly one argument (0 given) Let's try sending some value. Python fill_list_using_yields () . send ( 'hello, generator' ) # TypeError: can't send non-None value to a just-started generator This also failed! In a way, it's good that this failed. In the above snippet, we're calling send on a fresh generator object fill_list_using_yields() which hasn't yet started executing. This means that the execution hasn't yet reached the first yield point. Only yield expressions can receive a value using send . So, the above snippet attempts to send the value 'hello, generator' even though the generator is not yet ready to receive the value. This is why we must send a value that is completely useless and None uniquely quailifies 3 . This is called priming the generator . Let's try again. This time, we'll send None the first time, and some other values second and third time. Python w = fill_list_using_yields () w_value_1 = w . send ( None ) # = next(w) w_value_2 = w . send ( 'alpha' ) w_value_3 = w . send ( 3659 ) # list_value=['alpha', 3659] print ( w_value_1 ) # None print ( w_value_2 ) # None print ( w_value_3 ) # None Voila! list_value was updated with the values we sent. Parentheses are important \u00b6 Removing the parentheses from the first two yield expressions would result in an immediate syntax error. Python def fill_list_using_yields_wrong (): list_value = [ yield , yield ] print ( 'list_value= {} ' . format ( str ( list_value ))) yield # File \"<ipython-input-60-985d7314e596>\", line 2 # list_value = [yield, yield] # ^ # SyntaxError: invalid syntax A yield expression must be enclosed within parentheses with only two exceptions, as shown below. Python def yield_parentheses_exceptions (): # Exception I: you can skip the parentheses value_1 = yield value_2 = yield 42 # Exception II: you can skip the parentheses yield yield 42 # Not Exceptions: you must use parentheses value_3 = 12 + ( yield ) value_3 = 12 + ( yield 42 ) print (( yield )) # This is what PEP 342 gets wrong isinstance (( yield ), dict ) # This is what PEP 342 gets wrong Note the use of double parentheses in print((yield)) above. This is necessary even though PEP 342 says otherwise. Sadly, PEP 342 is outdated and contains some incorrect information. When in doubt, the documentation for your python version should provide some guidance. Why was the first example more difficult to run? \u00b6 This is simply because calling next on yield_is_an_expression would fail on the third try. Python q = yield_is_an_expression () next ( q ) # 1 next ( q ) # 2 next ( q ) # TypeError: unsupported operand type(s) for *: 'NoneType' and 'NoneType' Calling next is equivalent to calling send(None) , as we saw previously. Eventually, the generator would attempt to compute product_value as the product of two None s which is unsupported, regardless of generators. This problem is not just for None s; we can recreate the problem if we sent back a dict and a list . Python e = yield_is_an_expression () next ( e ) # prime the generator # 1 e . send ({ 'a' }) # 2 e . send ([ 1 ]) # TypeError: can't multiply sequence by non-int of type 'set' So, in order to drive yield_is_an_expression , we must send back values that support the product operation, such as ['a'] and 3 . Python f = yield_is_an_expression () next ( f ) # 1 f . send ([ 'a' ]) # 2 f . send ( 3 ) # no error The following is another working example that may be helpful because it shows the order in which data is sent back and forth. Python def sum_of_yields (): sum_value = ( yield 'send first value' ) + ( yield 'send second value' ) print ( 'sum_value= {} ' . format ( sum_value )) yield w = sum_of_yields () w_value_1 = next ( w ) print ( w_value_1 ) # send first value w_value_2 = w . send ( 100 ) print ( w_value_2 ) # send second value w_value_3 = w . send ( 23 ) # sum_value=123 print ( w_value_3 ) # None Can a function have both yield and return ? \u00b6 Yes, it can. Let's see two cases. return before a yield \u00b6 Even if we put a return before the first yield , the resulting function is still a generator function. Python def return_before_yield (): print ( 'Beginning' ) return print ( 'After return but before yield' ) yield print ( 'End' ) weird_gen_object = return_before_yield () print ( weird_gen_object ) # <generator object return_before_yield at 0x10807a120> next ( weird_gen_object ) # Beginning # --------------------------------------------------------------------------- # StopIteration Traceback (most recent call last) # <ipython-input-79-a5dbbac1bc45> in <module> # ----> 1 next(weird_gen_object) # StopIteration: This is another case of yield under an impossible branch . Obviously, we will never to reach the yield point because the generator function will return permanently when it reaches return . Thus, when return is before all the yield s, then the function is a generator function and has to be driven like a generator but behaves partially like a simple function by permanently returning when it hits return . return after all yield s \u00b6 FILL ME IN See https://www.python.org/dev/peps/pep-0380/: return value = raise StopIteration(value) StopIteration error \u00b6 FILL ME IN Can yield be outside a function? \u00b6 No 4 . This can be easily checked and is mentioned in the documentation . Python yield 1 # File \"<ipython-input-13-9f4dce03671c>\", line 1 # yield 1 # ^ # SyntaxError: 'yield' outside function ( yield 1 ) # File \"<ipython-input-80-4cb37392add7>\", line 1 # (yield 1) # ^ # SyntaxError: 'yield' outside function class A : ( yield 1 ) # File \"<ipython-input-81-f2ee79229f43>\", line 2 # (yield 1) # ^ # SyntaxError: 'yield' outside function Can a lambda contain a yield ? \u00b6 Yes. But, we must use yield within parentheses . Python # Fails lambda x : yield 'whatever' # SyntaxError: invalid syntax # Works gen_function_via_lambda = lambda : ( yield 1 ) print ( type ( gen_function_via_lambda ())) # <class 'generator'> In fact, python source uses a lambda to obtain generator type for use for collections.abc.Generator . Python generator = type (( lambda : ( yield ))()) print ( generator ) # <class 'generator'> Can you put a yield within a simple function? \u00b6 The answer to this question seems to be \"no\", given that we hammered this point repeatedly. But, this is a trick question, perhaps, for job interviews. Think about it and then click on Answer below to check for one possible answer. Answer Yes, just put the yield within another function inside a simple function. Python def this_is_a_simple_function (): print ( 'Entering simple function' ) def this_is_a_generator_function (): print ( 'Entering generator function' ) yield 1 print ( 'Exiting generator function' ) print ( 'Exiting simple function' ) return 'done' output = this_is_a_simple_function () # Entering simple function # Exiting simple function print ( output ) # done Can a simple function return a generator object? \u00b6 Another trick question for job interviews. Think about it and then click on Answer below. Answer Yes. See below. Python def simple_function_returns_gen_object (): print ( 'Entering simple function' ) def generator_function (): print ( 'Entering generator function' ) yield 1 print ( 'Exiting generator function' ) print ( 'Exiting simple function' ) return generator_function () obj = simple_function_returns_gen_object () # Entering simple function # Exiting simple function print ( obj ) # <generator object simple_function_returns_gen_object.<locals>.generator_function at 0x107fe19e0> This demonstrates an important point. Just because a function f returns a generator object does not mean that f is guaranteed to be a generator function. Can a simple function return a generator object without using yield inside it ? \u00b6 Another trick question for job interviews. Think about it and then click on Answer below. Answer Yes. Just move the generator function out. Python def some_generator_function (): yield 1 def simple_function_no_yield (): print ( 'Entering simple function' ) print ( 'Exiting simple function' ) return some_generator_function () obj = simple_function_no_yield () # Entering simple function # Exiting simple function print ( obj ) # <generator object some_generator_function at 0x10810aba0> Can a simple function return a generator object without using yield at all ? \u00b6 Another trick question for job interviews. Think about it and then click on Answer below. Answer Yes. Define a generator class which avoids the use of yield . Python from collections.abc import Generator def simple_function_no_yield_self_contained (): print ( 'Entering simple function' ) class SomeGeneratorClass ( Generator ): def send ( self , value ): super () . send ( value ) def throw ( self , typ , val = None , tb = None ): super () . throw ( typ , val , tb ) print ( 'Exiting simple function' ) return SomeGeneratorClass () obj = simple_function_no_yield_self_contained () # Entering simple function # Exiting simple function print ( obj ) # <__main__.simple_function_no_yield_self_contained.<locals>.SomeGeneratorClass object at 0x107f92d90> Footnotes \u00b6 It's like we can never win with yield . Pick a side, yield ! \u21a9 We don't always need something to evaluate to True to choose the if branch instead of the else branch. For example, non-zero int s or float s, non-empty lists, and non-empty strings all evaluate to True . Similarly, 0 , empty lists, and empty strings evaluate to False . \u21a9 You could argue that we could've allowed sending 'hello, generator' the first time and then just thrown it away. That would certainly be possible but it would make for a poorer design. First, every programmer could send something different leading to unnecessary and useless magic strings in the code. Second, anybody reading the code would be confused as to why a particular first, throwaway value was chosen and whether or not it had any significance. And, finally, unnecessarily sending an object only to be thrown away would waste computation. \u21a9 Think of yield as a fish. It cannot survive outside the waters of a function . \u21a9","title":"Mechanics by Examples"},{"location":"generators/mechanics-by-examples/#mechanics-by-examples","text":"Curious readers may have lots of questions on how exactly yield behaves. Let's answer them with examples.","title":"Mechanics by Examples"},{"location":"generators/mechanics-by-examples/#yield-under-an-impossible-branch","text":"In Introduction , we said that a syntactically reachable yield within a function makes it a generator function. The important word is syntactically . So, even if a yield statement is inside a never-to-be-executed if branch, such as shown below, the function would still be a generator function. Python def still_a_generator_function (): print ( 'Entering' ) if False : yield 1 print ( 'Exiting' ) x = still_a_generator_function () print ( type ( x )) # <class 'generator'> next ( x ) # Entering # Exiting # --------------------------------------------------------------------------- # StopIteration Traceback (most recent call last) # <ipython-input-4-92de4e9f6b1e> in <module> # ----> 1 next(x) # StopIteration: The above generator function is indeed quite strange. The yield statment will never get to execute because it is under an impossible if branch, and yet, presence of the yield keyword makes for a generator function. Then, when, we call next on the generator function, it does not find even a single yield statement (where the execution could've been suspended), reaches the end of the function, and throws a StopIteration 1 . Allowing an impossible to reach yield to create a generator is still a reasonable decision. This is because in a more real-world example, the python interpreter can never know which way an if statement would resolve. Consider the following snippet. Python def real_world_function (): # ... if some_variable . some_method (): yield something else : # Do anything but yield There is no way of knowing whether some_variable.some_method() would be considered equivalent to True or not. What if some_variable.some_method() uses pseudo random numbers and can return a True -equivalent 2 during some runs and a False -equivalent during some other runs? Even if some_variable.some_method() does not use random numbers, code changes in this method would affect which branch of if-else is executed inside real_world_function . Programmers would also face the same exact problem as the interpreter. How would you write the downstream code to execute the contents of real_world_function ? We've already seen that we require very different code to drive a generator function versus running a simple function. The same applies to other control flow constructs such as while and do while or even something as evil as this. Python def evil_generator_function (): while True : pass yield 1 This behavior can also be used to your advantage when you're editing code. Suppose that you have a generator function called frequently_edited_gen_fun . You've written downstream code to use frequently_edited_gen_fun as a generator function. Now, you need to edit it and as a result of this edit, you have to remove all the yield statements. Removing all yield statements would reduce frequently_edited_gen_fun to a simple function causing all the downstream code to fail unless rewritten. You can salvage the situation by adding an impossible to reach yield like the one shown in one of the examples above. This yield would never be reached but it will still prevent frequently_edited_gen_fun from becoming a simple function. MENTION THAT REJECTED PIP HERE (COFUNCTIONS, WAS IT?). See yet another example in return before a yield .","title":"yield under an impossible branch"},{"location":"generators/mechanics-by-examples/#must-we-return-something-with-yield","text":"No. We can yield without specifying a yield value. Python def no_yield_value (): print ( 'Entering' ) yield print ( 'Exiting' ) y = no_yield_value () y_yield_value = next ( y ) # Entering print ( y_yield_value ) # None If we don't specify a yield value, None is yielded. This is similar to return in the following simple function. Python def no_return_value (): return no_return_value () is None # True","title":"Must we return something with yield?"},{"location":"generators/mechanics-by-examples/#yield-is-an-expression","text":"Since PEP 342 , yield is an expression rather than a statement, even if it can be used in a statement form. Python def yield_is_an_expression (): product_value = ( yield 1 ) * ( yield 2 ) # expression form yield 3 # statement form The above code is legal syntax. You should try this out yourself because things will become murky in a moment. We've already seen that we can send value into a a generator via the yield keyword. The above generator function seems to compute product_value as a sum of two yield expressions. Only difference is that this time the expressions are wrapped in parentheses. This is also important. Thw following statements list the rules of engagement when it comes to yield . yield is always an expression, even if it can be written in a statement form (like a return statement) yield expressions almost always require parentheses with two known exceptions. Overuse of parentheses is encouraged. Every yield expression has a value, even if the value is None . Let's look at an example that is easier to run than the one above. We'll discuss why this example is easier than the one above in a moment. Python def fill_list_using_yields (): list_value = [( yield ), ( yield )] print ( 'list_value= {} ' . format ( str ( list_value ))) yield","title":"yield is an expression"},{"location":"generators/mechanics-by-examples/#drive-using-next","text":"We can drive the above generator in at least two ways, one is using next and the other using send . Let's see next first. Python z = fill_list_using_yields () z_value_1 = next ( z ) z_value_2 = next ( z ) z_value_3 = next ( z ) # list_value=[None, None] In the above snippet, we didn't explicitly send any value to the generator and it appears that the generator assumed that we sent back None s. There is an important but simple reason for this. Calling the next function calls the __next__ method. If this __next__ is the default method (which is indeed the case for fill_list_using_yields ), then __next__ simply calls the send method with a None argument. Thus, calling next(z) is equivalent to calling z.__next__() , which is equivalent to calling z.send(None) . This clarifies why list_value contains None s. If we were to redefine __next__ , perhaps by defining a generator class, then the outcome could've been different.","title":"Drive using next"},{"location":"generators/mechanics-by-examples/#drive-using-send","text":"Let's look at send now. When we use the send method, we explicitly send back a value to the generator. Expectedly, trying to call send without any argument fails. Python fill_list_using_yields () . send () # TypeError: send() takes exactly one argument (0 given) Let's try sending some value. Python fill_list_using_yields () . send ( 'hello, generator' ) # TypeError: can't send non-None value to a just-started generator This also failed! In a way, it's good that this failed. In the above snippet, we're calling send on a fresh generator object fill_list_using_yields() which hasn't yet started executing. This means that the execution hasn't yet reached the first yield point. Only yield expressions can receive a value using send . So, the above snippet attempts to send the value 'hello, generator' even though the generator is not yet ready to receive the value. This is why we must send a value that is completely useless and None uniquely quailifies 3 . This is called priming the generator . Let's try again. This time, we'll send None the first time, and some other values second and third time. Python w = fill_list_using_yields () w_value_1 = w . send ( None ) # = next(w) w_value_2 = w . send ( 'alpha' ) w_value_3 = w . send ( 3659 ) # list_value=['alpha', 3659] print ( w_value_1 ) # None print ( w_value_2 ) # None print ( w_value_3 ) # None Voila! list_value was updated with the values we sent.","title":"Drive using send"},{"location":"generators/mechanics-by-examples/#parentheses-are-important","text":"Removing the parentheses from the first two yield expressions would result in an immediate syntax error. Python def fill_list_using_yields_wrong (): list_value = [ yield , yield ] print ( 'list_value= {} ' . format ( str ( list_value ))) yield # File \"<ipython-input-60-985d7314e596>\", line 2 # list_value = [yield, yield] # ^ # SyntaxError: invalid syntax A yield expression must be enclosed within parentheses with only two exceptions, as shown below. Python def yield_parentheses_exceptions (): # Exception I: you can skip the parentheses value_1 = yield value_2 = yield 42 # Exception II: you can skip the parentheses yield yield 42 # Not Exceptions: you must use parentheses value_3 = 12 + ( yield ) value_3 = 12 + ( yield 42 ) print (( yield )) # This is what PEP 342 gets wrong isinstance (( yield ), dict ) # This is what PEP 342 gets wrong Note the use of double parentheses in print((yield)) above. This is necessary even though PEP 342 says otherwise. Sadly, PEP 342 is outdated and contains some incorrect information. When in doubt, the documentation for your python version should provide some guidance.","title":"Parentheses are important"},{"location":"generators/mechanics-by-examples/#why-was-the-first-example-more-difficult-to-run","text":"This is simply because calling next on yield_is_an_expression would fail on the third try. Python q = yield_is_an_expression () next ( q ) # 1 next ( q ) # 2 next ( q ) # TypeError: unsupported operand type(s) for *: 'NoneType' and 'NoneType' Calling next is equivalent to calling send(None) , as we saw previously. Eventually, the generator would attempt to compute product_value as the product of two None s which is unsupported, regardless of generators. This problem is not just for None s; we can recreate the problem if we sent back a dict and a list . Python e = yield_is_an_expression () next ( e ) # prime the generator # 1 e . send ({ 'a' }) # 2 e . send ([ 1 ]) # TypeError: can't multiply sequence by non-int of type 'set' So, in order to drive yield_is_an_expression , we must send back values that support the product operation, such as ['a'] and 3 . Python f = yield_is_an_expression () next ( f ) # 1 f . send ([ 'a' ]) # 2 f . send ( 3 ) # no error The following is another working example that may be helpful because it shows the order in which data is sent back and forth. Python def sum_of_yields (): sum_value = ( yield 'send first value' ) + ( yield 'send second value' ) print ( 'sum_value= {} ' . format ( sum_value )) yield w = sum_of_yields () w_value_1 = next ( w ) print ( w_value_1 ) # send first value w_value_2 = w . send ( 100 ) print ( w_value_2 ) # send second value w_value_3 = w . send ( 23 ) # sum_value=123 print ( w_value_3 ) # None","title":"Why was the first example more difficult to run?"},{"location":"generators/mechanics-by-examples/#can-a-function-have-both-yield-and-return","text":"Yes, it can. Let's see two cases.","title":"Can a function have both yield and return?"},{"location":"generators/mechanics-by-examples/#return-before-a-yield","text":"Even if we put a return before the first yield , the resulting function is still a generator function. Python def return_before_yield (): print ( 'Beginning' ) return print ( 'After return but before yield' ) yield print ( 'End' ) weird_gen_object = return_before_yield () print ( weird_gen_object ) # <generator object return_before_yield at 0x10807a120> next ( weird_gen_object ) # Beginning # --------------------------------------------------------------------------- # StopIteration Traceback (most recent call last) # <ipython-input-79-a5dbbac1bc45> in <module> # ----> 1 next(weird_gen_object) # StopIteration: This is another case of yield under an impossible branch . Obviously, we will never to reach the yield point because the generator function will return permanently when it reaches return . Thus, when return is before all the yield s, then the function is a generator function and has to be driven like a generator but behaves partially like a simple function by permanently returning when it hits return .","title":"return before a yield"},{"location":"generators/mechanics-by-examples/#return-after-all-yields","text":"FILL ME IN See https://www.python.org/dev/peps/pep-0380/: return value = raise StopIteration(value)","title":"return after all yields"},{"location":"generators/mechanics-by-examples/#stopiteration-error","text":"FILL ME IN","title":"StopIteration error"},{"location":"generators/mechanics-by-examples/#can-yield-be-outside-a-function","text":"No 4 . This can be easily checked and is mentioned in the documentation . Python yield 1 # File \"<ipython-input-13-9f4dce03671c>\", line 1 # yield 1 # ^ # SyntaxError: 'yield' outside function ( yield 1 ) # File \"<ipython-input-80-4cb37392add7>\", line 1 # (yield 1) # ^ # SyntaxError: 'yield' outside function class A : ( yield 1 ) # File \"<ipython-input-81-f2ee79229f43>\", line 2 # (yield 1) # ^ # SyntaxError: 'yield' outside function","title":"Can yield be outside a function?"},{"location":"generators/mechanics-by-examples/#can-a-lambda-contain-a-yield","text":"Yes. But, we must use yield within parentheses . Python # Fails lambda x : yield 'whatever' # SyntaxError: invalid syntax # Works gen_function_via_lambda = lambda : ( yield 1 ) print ( type ( gen_function_via_lambda ())) # <class 'generator'> In fact, python source uses a lambda to obtain generator type for use for collections.abc.Generator . Python generator = type (( lambda : ( yield ))()) print ( generator ) # <class 'generator'>","title":"Can a lambda contain a yield?"},{"location":"generators/mechanics-by-examples/#can-you-put-a-yield-within-a-simple-function","text":"The answer to this question seems to be \"no\", given that we hammered this point repeatedly. But, this is a trick question, perhaps, for job interviews. Think about it and then click on Answer below to check for one possible answer. Answer Yes, just put the yield within another function inside a simple function. Python def this_is_a_simple_function (): print ( 'Entering simple function' ) def this_is_a_generator_function (): print ( 'Entering generator function' ) yield 1 print ( 'Exiting generator function' ) print ( 'Exiting simple function' ) return 'done' output = this_is_a_simple_function () # Entering simple function # Exiting simple function print ( output ) # done","title":"Can you put a yield within a simple function?"},{"location":"generators/mechanics-by-examples/#can-a-simple-function-return-a-generator-object","text":"Another trick question for job interviews. Think about it and then click on Answer below. Answer Yes. See below. Python def simple_function_returns_gen_object (): print ( 'Entering simple function' ) def generator_function (): print ( 'Entering generator function' ) yield 1 print ( 'Exiting generator function' ) print ( 'Exiting simple function' ) return generator_function () obj = simple_function_returns_gen_object () # Entering simple function # Exiting simple function print ( obj ) # <generator object simple_function_returns_gen_object.<locals>.generator_function at 0x107fe19e0> This demonstrates an important point. Just because a function f returns a generator object does not mean that f is guaranteed to be a generator function.","title":"Can a simple function return a generator object?"},{"location":"generators/mechanics-by-examples/#can-a-simple-function-return-a-generator-object-without-using-yield-inside-it","text":"Another trick question for job interviews. Think about it and then click on Answer below. Answer Yes. Just move the generator function out. Python def some_generator_function (): yield 1 def simple_function_no_yield (): print ( 'Entering simple function' ) print ( 'Exiting simple function' ) return some_generator_function () obj = simple_function_no_yield () # Entering simple function # Exiting simple function print ( obj ) # <generator object some_generator_function at 0x10810aba0>","title":"Can a simple function return a generator object without using yield inside it?"},{"location":"generators/mechanics-by-examples/#can-a-simple-function-return-a-generator-object-without-using-yield-at-all","text":"Another trick question for job interviews. Think about it and then click on Answer below. Answer Yes. Define a generator class which avoids the use of yield . Python from collections.abc import Generator def simple_function_no_yield_self_contained (): print ( 'Entering simple function' ) class SomeGeneratorClass ( Generator ): def send ( self , value ): super () . send ( value ) def throw ( self , typ , val = None , tb = None ): super () . throw ( typ , val , tb ) print ( 'Exiting simple function' ) return SomeGeneratorClass () obj = simple_function_no_yield_self_contained () # Entering simple function # Exiting simple function print ( obj ) # <__main__.simple_function_no_yield_self_contained.<locals>.SomeGeneratorClass object at 0x107f92d90>","title":"Can a simple function return a generator object without using yield at all?"},{"location":"generators/mechanics-by-examples/#footnotes","text":"It's like we can never win with yield . Pick a side, yield ! \u21a9 We don't always need something to evaluate to True to choose the if branch instead of the else branch. For example, non-zero int s or float s, non-empty lists, and non-empty strings all evaluate to True . Similarly, 0 , empty lists, and empty strings evaluate to False . \u21a9 You could argue that we could've allowed sending 'hello, generator' the first time and then just thrown it away. That would certainly be possible but it would make for a poorer design. First, every programmer could send something different leading to unnecessary and useless magic strings in the code. Second, anybody reading the code would be confused as to why a particular first, throwaway value was chosen and whether or not it had any significance. And, finally, unnecessarily sending an object only to be thrown away would waste computation. \u21a9 Think of yield as a fish. It cannot survive outside the waters of a function . \u21a9","title":"Footnotes"},{"location":"generators/yield-from/","text":"yield from \u00b6 We saw previously that presence or absence of a syntactically reachable yield within a function can change the nature of the function completely. Adding a yield makes the function into a generator function and removing the yield makes the function a simple function. We also discussed that this yield -induced structural change can cause the entire downstream code to be rewritten. This yield -induced structural change is a big problem when refactoring code. Let's look at a toy 1 example to understand this issue. The following example generates random shades of red and random shades of blue as (r, g, b) tuples. Python import random def generate_red_blue ( n = 2 ): while True : # Generate n shades of red for _ in range ( n ): r = random . randint ( 1 , 255 ) gb = random . randint ( 0 , r - 1 ) yield ( r , gb , gb ) # Generate n shades of blue for _ in range ( n ): b = random . randint ( 1 , 255 ) rg = random . randint ( 0 , b - 1 ) yield ( rg , rg , b ) x = generate_red_blue () next ( x ) # (105, 75, 75) # red next ( x ) # (205, 125, 125) # red next ( x ) # (108, 108, 225) # blue next ( x ) # (143, 143, 206) # blue You can execute the generator function generate_red_blue yourself to see how it works. Consider the situation that you need another generator function to generate shades of red and green. You could write another function, say, generate_red_green by copying the red section of generate_red_blue . This would generally be a bad programming practice for various reasons. For example, if we wanted to replace the current red scheme with a better scheme, we will have to edit two functions. Expectedly, we should extract out the red section into a generator of its own. This does not pose a problem, yet. Now, if we wanted yet another function to generate shades of green and blue , we would need to extract the blue section into another generator function of its own. Extracting out both red and blue sections would remove the two yield statements from generate_red_blue , which would reduce it to a simple function. This would require a rewrite of the downstream code, as we've discussed before . Naive Solution \u00b6 We can solve the problem by instantiating the generator objects within generate_red_blue and then yield ourselves, as shown below. Python import random def generate_red ( n = 2 ): for _ in range ( n ): r = random . randint ( 1 , 255 ) gb = random . randint ( 0 , r - 1 ) yield ( r , gb , gb ) def generate_blue ( n = 2 ): for _ in range ( n ): b = random . randint ( 1 , 255 ) rg = random . randint ( 0 , b - 1 ) yield ( rg , rg , b ) def generate_red_blue_refactored_basic ( n = 2 ): while True : for red in generate_red ( n ): yield red for blue in generate_blue ( n ): yield blue y = generate_red_blue_refactored_basic () next ( y ) # (159, 8, 8) # red next ( y ) # (64, 40, 40) # red next ( y ) # (54, 54, 157) # blue next ( y ) # (0, 0, 198) # blue This works, as you can check yourself. But, the code above has a problem. For example, if we send a value to generate_red_blue_refactored_basic , it would not automatically get sent to generate_red or generate_blue ; we will have to update generate_red_blue_refactored_basic to send any value it receives to the subgenerators generate_red and generate_blue . Another problem is the use of other generator functions, throw and close . Better Solution \u00b6 Handling all of these cases is non-trivial yet boilerplate. This is why PEP 380 added a new syntax called yield from . The generate_red and generate_blue are defined just like in the naive solution above. The refactored, yield from -based generator function is below. Python def generate_red_blue_refactored ( n = 2 ): while True : yield from generate_red ( n ) yield from generate_blue ( n ) z = generate_red_blue_refactored () next ( z ) # (60, 58, 58) # red next ( z ) # (64, 43, 43) # red next ( z ) # (155, 155, 200) # blue next ( z ) # (56, 56, 59) # blue On its face, yield from seems to provide a marginal improvement in brevity. The generator function generate_red_blue_refactored_basic was quite terse to begin with and generate_red_blue_refactored only removes the simple for loops. However, by using yield from , generate_red_blue_refactored allows sending values back to the subgenerators and a proper handling of exceptions. If we were to add these benefits to our basic solution in generate_red_blue_refactored_basic , we would have to write a lot of code such as the one shown in PEP 380 . yield from still makes a generator function As you may have noticed, a function containing a syntactically reachable yield from is still a generator function (which is an extended, not a simple function). The same rules apply as that for yield . yield from is a QoL improvement \u00b6 If you review PEP 380 , you'll find that yield from is semantically equivalent to a small snippet of regular python code that contains a lot of try - catch statements. Thus, yield from is simply a quality of life improvement with only new python magic being the new keyword yield from . yield from to write generator-based coroutines \u00b6 It is true that yield from has a special usage: it can be used to write generator-based coroutines. We don't talk about generator-based coroutines in this course for many reasons. Firstly, generator-based coroutines are deprecated and scheduled for removal in Python 3.10. It's no longer need to learn asynchronous programming in python. Secondly, even the term generator-based coroutines causes so much confusion ; is it a generator, is it a coroutine, is it both, or is it neither? See the footnote in Control and the footnote in Introduction for even more details. We recommend beginners to forget that generator-based coroutines exist or that yield from has a special usage to create them. There is nothing to lose by doing so. Footnotes \u00b6 This example is quite silly. Some would argue that the (r, g, b) tuples being returned are not even shades of red/blue and they would be right. Such a scheme to determine shades of red/blue is definitely not something to be used in real world code. For example, (72, 218, 223) can be considered blue but it won't be returned by our example. If you want a more real world example demonstrating the benefits of yield from , consider the Fibonacci server that David Beazley coded live . \u21a9","title":"yield from"},{"location":"generators/yield-from/#yield-from","text":"We saw previously that presence or absence of a syntactically reachable yield within a function can change the nature of the function completely. Adding a yield makes the function into a generator function and removing the yield makes the function a simple function. We also discussed that this yield -induced structural change can cause the entire downstream code to be rewritten. This yield -induced structural change is a big problem when refactoring code. Let's look at a toy 1 example to understand this issue. The following example generates random shades of red and random shades of blue as (r, g, b) tuples. Python import random def generate_red_blue ( n = 2 ): while True : # Generate n shades of red for _ in range ( n ): r = random . randint ( 1 , 255 ) gb = random . randint ( 0 , r - 1 ) yield ( r , gb , gb ) # Generate n shades of blue for _ in range ( n ): b = random . randint ( 1 , 255 ) rg = random . randint ( 0 , b - 1 ) yield ( rg , rg , b ) x = generate_red_blue () next ( x ) # (105, 75, 75) # red next ( x ) # (205, 125, 125) # red next ( x ) # (108, 108, 225) # blue next ( x ) # (143, 143, 206) # blue You can execute the generator function generate_red_blue yourself to see how it works. Consider the situation that you need another generator function to generate shades of red and green. You could write another function, say, generate_red_green by copying the red section of generate_red_blue . This would generally be a bad programming practice for various reasons. For example, if we wanted to replace the current red scheme with a better scheme, we will have to edit two functions. Expectedly, we should extract out the red section into a generator of its own. This does not pose a problem, yet. Now, if we wanted yet another function to generate shades of green and blue , we would need to extract the blue section into another generator function of its own. Extracting out both red and blue sections would remove the two yield statements from generate_red_blue , which would reduce it to a simple function. This would require a rewrite of the downstream code, as we've discussed before .","title":"yield from"},{"location":"generators/yield-from/#naive-solution","text":"We can solve the problem by instantiating the generator objects within generate_red_blue and then yield ourselves, as shown below. Python import random def generate_red ( n = 2 ): for _ in range ( n ): r = random . randint ( 1 , 255 ) gb = random . randint ( 0 , r - 1 ) yield ( r , gb , gb ) def generate_blue ( n = 2 ): for _ in range ( n ): b = random . randint ( 1 , 255 ) rg = random . randint ( 0 , b - 1 ) yield ( rg , rg , b ) def generate_red_blue_refactored_basic ( n = 2 ): while True : for red in generate_red ( n ): yield red for blue in generate_blue ( n ): yield blue y = generate_red_blue_refactored_basic () next ( y ) # (159, 8, 8) # red next ( y ) # (64, 40, 40) # red next ( y ) # (54, 54, 157) # blue next ( y ) # (0, 0, 198) # blue This works, as you can check yourself. But, the code above has a problem. For example, if we send a value to generate_red_blue_refactored_basic , it would not automatically get sent to generate_red or generate_blue ; we will have to update generate_red_blue_refactored_basic to send any value it receives to the subgenerators generate_red and generate_blue . Another problem is the use of other generator functions, throw and close .","title":"Naive Solution"},{"location":"generators/yield-from/#better-solution","text":"Handling all of these cases is non-trivial yet boilerplate. This is why PEP 380 added a new syntax called yield from . The generate_red and generate_blue are defined just like in the naive solution above. The refactored, yield from -based generator function is below. Python def generate_red_blue_refactored ( n = 2 ): while True : yield from generate_red ( n ) yield from generate_blue ( n ) z = generate_red_blue_refactored () next ( z ) # (60, 58, 58) # red next ( z ) # (64, 43, 43) # red next ( z ) # (155, 155, 200) # blue next ( z ) # (56, 56, 59) # blue On its face, yield from seems to provide a marginal improvement in brevity. The generator function generate_red_blue_refactored_basic was quite terse to begin with and generate_red_blue_refactored only removes the simple for loops. However, by using yield from , generate_red_blue_refactored allows sending values back to the subgenerators and a proper handling of exceptions. If we were to add these benefits to our basic solution in generate_red_blue_refactored_basic , we would have to write a lot of code such as the one shown in PEP 380 . yield from still makes a generator function As you may have noticed, a function containing a syntactically reachable yield from is still a generator function (which is an extended, not a simple function). The same rules apply as that for yield .","title":"Better Solution"},{"location":"generators/yield-from/#yield-from-is-a-qol-improvement","text":"If you review PEP 380 , you'll find that yield from is semantically equivalent to a small snippet of regular python code that contains a lot of try - catch statements. Thus, yield from is simply a quality of life improvement with only new python magic being the new keyword yield from .","title":"yield from is a QoL improvement"},{"location":"generators/yield-from/#yield-from-to-write-generator-based-coroutines","text":"It is true that yield from has a special usage: it can be used to write generator-based coroutines. We don't talk about generator-based coroutines in this course for many reasons. Firstly, generator-based coroutines are deprecated and scheduled for removal in Python 3.10. It's no longer need to learn asynchronous programming in python. Secondly, even the term generator-based coroutines causes so much confusion ; is it a generator, is it a coroutine, is it both, or is it neither? See the footnote in Control and the footnote in Introduction for even more details. We recommend beginners to forget that generator-based coroutines exist or that yield from has a special usage to create them. There is nothing to lose by doing so.","title":"yield from to write generator-based coroutines"},{"location":"generators/yield-from/#footnotes","text":"This example is quite silly. Some would argue that the (r, g, b) tuples being returned are not even shades of red/blue and they would be right. Such a scheme to determine shades of red/blue is definitely not something to be used in real world code. For example, (72, 218, 223) can be considered blue but it won't be returned by our example. If you want a more real world example demonstrating the benefits of yield from , consider the Fibonacci server that David Beazley coded live . \u21a9","title":"Footnotes"},{"location":"review/async-for-with/","text":"","title":"Async for with"},{"location":"review/asynchronous-generator/","text":"","title":"Asynchronous Generator"},{"location":"review/generators-v-coroutines/","text":"Generators v Coroutines \u00b6 TBD Generators \u00b6 Implements Iterator Generators yes Coroutines no Can be used with a for loop Have send, throw, close methods Coroutines \u00b6 Implements Awaitable Can be used with an event loop Have send, throw, close methods","title":"Generators vs Coroutines"},{"location":"review/generators-v-coroutines/#generators-v-coroutines","text":"TBD","title":"Generators v Coroutines"},{"location":"review/generators-v-coroutines/#generators","text":"Implements Iterator Generators yes Coroutines no Can be used with a for loop Have send, throw, close methods","title":"Generators"},{"location":"review/generators-v-coroutines/#coroutines","text":"Implements Awaitable Can be used with an event loop Have send, throw, close methods","title":"Coroutines"},{"location":"review/nuggets/","text":"","title":"Nuggets"},{"location":"suspendables/buying-a-plane-ticket/","text":"Buying a plane ticket \u00b6 Let's look at a classic example \u2014 network calls. Suppose we want to buy a plane ticket. The same plane ticket is available for purchase, albeit at different prices, from three online vendors \u2014 Vendor Red, Vendor Green, and Vendor Blue. We need to query each vendor to get the ticket price so as to find the cheapest ticket. This classic example is often used to demonstrate the need for asynchronous programming itself. The need for asynchronous programming \u00b6 Serial & synchronous \u00b6 We could do this task serially and synchronously \u2014 send a request to one server, wait for it to reply, and send another request to another server and wait for it to reply and then the same for the third server. Now, that we have the prices from all three servers, we can find the lowest price. Pseudocode function get_price ( vendor ) request = create_request ( vendor ) request . wait () print ( f 'Received price from the vendor { vendor } !' ) return request . result red_price = get_price ( red ) # Wait 1000ms blue_price = get_price ( blue ) # Wait another 300ms green_price = get_price ( green ) # Wait yet another 400ms best_price = min ([ red_price , green_price , blue_price ]) This approach is wasteful. The table below shows the times taken by each vendor to reply to our query. No matter how we order the three vendors, serial and synchronous approach is guaranteed to take 1700 ms, which is the sum of the three individual query times. Vendor Query time Total time Red 1000 ms Green 300 ms Blue 400 ms 1700 ms Parallel & synchronous \u00b6 This approach is similar to the serial & synchronous approach except that we execute the three queries parallely. But, each query is still synchronous in the sense that we wait for that query to finish before doing anything downstream. Depending on the programming language, we can implement parallelism using either processes and threads. The pseudocode below uses processes. Pseudocode function get_price ( vendor ) request = create_request ( vendor ) request . wait () print ( f 'Received price from the vendor { vendor } !' ) return request . result p_red = Process ( get_price , args = ( red , )) p_green = Process ( get_price , args = ( green , )) p_blue = Process ( get_price , args = ( blue , )) # Start the processes p_red . start () p_green . start () p_blue . start () p_red . join () # Waits 1000ms p_green . join () # No wait; we've already waited 300ms p_blue . join () # No wait; we've already waited 400ms red_price , green_price , blue_price = p_red . result , p_green . result , p_blue . result best_price = min ([ red_price , green_price , blue_price ]) All three queries are dispatched at roughly the same time, when we call the corresponding p_vendor>.start() methods. We then wait for the query to Vendor Red to finish first, when we call p_red.join() , which takes 1000ms. During these 1000ms, the queries to Vendors Blue and Green, which take 300ms and 400ms respectively, have already finished. So, we don't have to wait on the vendors when we call p_green.join() and p_blue.join() . Overall, this approach takes a 1000ms, which is obviously better than the serial & synchronous approach. Vendor Query time Total time Red 1000 ms Green 300 ms Blue 400 ms 1000 ms But, this approach is still on resources. Each process takes separate memory to run. Each process also needs time to be setup. Depending on the machine, we may not have 3 processes to spare. And, in a real-world case, such as for our own Kayak-type website, we may have thousands of queries that need to be run parallely. We don't have a machine that has thousands of processors. And, even if we did, creating thousands of processes would have trememdous overhead which would negate any multiprocessing gains. We could use a worker pool of three processes that rotates through thousands of queries three at a time. This three-at-a-time parallelism would still take a long time to work through thousands of queries because only three queries would be active at a time. Alternatively, we could use threads (within the main process) to implement the parallelism. Threads share memory and can be started and ended much faster than processes. Obviously, in the default CPython, this would not be truly parallel because the Global Interpreter Lock only allows one thread to have access to the interpreter at one time. There are different Python implementations that do not have a GIL. IronPython is one such example. In a GIL-free python implementation, the threads may be able to behave truly parallely. Our toy example only needs three threads and would definitely benefit from a GIL-free implementation. However, our own Kayak-type website would require thousands of threads, which is more efficient than thousands of processes, but is still not efficient enough. Thousands of threads may not even be possible on a machine. We could use a worker pool of three threads that rotates through thousands of queries three at a time. As with processes, this three-at-a-time GIL-free parallelism would still take a long time to work through thousands of queries because only three queries would be active at a time. There is room for improvement \u00b6 Servers have internal latencies and transferring data over the network takes time. We don't need to perform a lot of computation, we simply need to receive the price data. There is no inherent need to create threads or processes simply to handle the incoming data. Before the advent of asychronous programming, we were forced to create multiple threads or processes because there was nothing better available. Not parallel & asynchronous \u00b6 This approach uses a single thread within a single process. We don't have the overhead of creating new threads or processes. The magic here is that we made the get_price function suspendable. The pseudocode below has janky syntax. This is purposeful as we will explain in the next section on syntax . For now, we will ignore the syntax issues and focus on how asychronous programming can solve our problem even more efficiently than parallelism. Pseudocode suspendable function get_price ( vendor ) request = create_request ( vendor ) release control # suspension/control transfer point request . wait () print ( f 'Received price from the vendor { vendor } !' ) return request . result # Initiate all requests but don't wait for them to finish get_price ( red ) get_price ( green ) get_price ( blue ) # Resume suspended functions and wait for them to complete red_price = get_price ( red ) . wait () # Waits 1000ms green_price = get_price ( green ) . wait () # No wait; we've already waited 300ms blue_price = get_price ( blue ) . wait () # No wait; we've already waited 400ms min ([ red_price , green_price , blue_price ]) # Did you notice the janky syntax in this pseudocode? This is why we need # to answer the syntax question in the next few section. We call get_price three times, once for each of the three vendors. This sends a query to each of the three vendor websites but doesn't immediately wait for the queries to be answered. Once all three queries have been sent, the pseudocode then waits for the queries to be answered in a particular, distinguished order -- it waits for red to finish, then green to finish, and then red to finish. Similar to the parallel & synchronous approach, we only have to wait a 1000ms in all. Vendor Query time Total time Red 1000 ms Green 300 ms Blue 400 ms 1000 ms Asynchronous approach is just as fast as the parallel & synchronous approach. But, asynchronous approach can handle thousands of queries within the same thread and the same process. Even if we had a thousand queries, we could start all of the queries nearly simultaneously without waiting for them to finish. Finally, let's not forget that we could still use process-based parallelism along side asychronous programming. Not just theoretical \u00b6 Nginx vs Apache provides a real-world, industrial-strength example where asynchronous programming outperforms parallelism via multithreading. Summary \u00b6 Approach Time Processes Threads Limited by Serial & Synchronous 1700 ms 1 1 - Parallel & Synchronous (Processes) 1000 ms 1 + 3 1 / process processor count Parallel & Synchronous (Threads, GIL-free) 1000 ms 1 1 + 3 processor count Asychronous 1000 ms 1 1 network bandwidth","title":"Buying a plane ticket"},{"location":"suspendables/buying-a-plane-ticket/#buying-a-plane-ticket","text":"Let's look at a classic example \u2014 network calls. Suppose we want to buy a plane ticket. The same plane ticket is available for purchase, albeit at different prices, from three online vendors \u2014 Vendor Red, Vendor Green, and Vendor Blue. We need to query each vendor to get the ticket price so as to find the cheapest ticket. This classic example is often used to demonstrate the need for asynchronous programming itself.","title":"Buying a plane ticket"},{"location":"suspendables/buying-a-plane-ticket/#the-need-for-asynchronous-programming","text":"","title":"The need for asynchronous programming"},{"location":"suspendables/buying-a-plane-ticket/#serial-synchronous","text":"We could do this task serially and synchronously \u2014 send a request to one server, wait for it to reply, and send another request to another server and wait for it to reply and then the same for the third server. Now, that we have the prices from all three servers, we can find the lowest price. Pseudocode function get_price ( vendor ) request = create_request ( vendor ) request . wait () print ( f 'Received price from the vendor { vendor } !' ) return request . result red_price = get_price ( red ) # Wait 1000ms blue_price = get_price ( blue ) # Wait another 300ms green_price = get_price ( green ) # Wait yet another 400ms best_price = min ([ red_price , green_price , blue_price ]) This approach is wasteful. The table below shows the times taken by each vendor to reply to our query. No matter how we order the three vendors, serial and synchronous approach is guaranteed to take 1700 ms, which is the sum of the three individual query times. Vendor Query time Total time Red 1000 ms Green 300 ms Blue 400 ms 1700 ms","title":"Serial &amp; synchronous"},{"location":"suspendables/buying-a-plane-ticket/#parallel-synchronous","text":"This approach is similar to the serial & synchronous approach except that we execute the three queries parallely. But, each query is still synchronous in the sense that we wait for that query to finish before doing anything downstream. Depending on the programming language, we can implement parallelism using either processes and threads. The pseudocode below uses processes. Pseudocode function get_price ( vendor ) request = create_request ( vendor ) request . wait () print ( f 'Received price from the vendor { vendor } !' ) return request . result p_red = Process ( get_price , args = ( red , )) p_green = Process ( get_price , args = ( green , )) p_blue = Process ( get_price , args = ( blue , )) # Start the processes p_red . start () p_green . start () p_blue . start () p_red . join () # Waits 1000ms p_green . join () # No wait; we've already waited 300ms p_blue . join () # No wait; we've already waited 400ms red_price , green_price , blue_price = p_red . result , p_green . result , p_blue . result best_price = min ([ red_price , green_price , blue_price ]) All three queries are dispatched at roughly the same time, when we call the corresponding p_vendor>.start() methods. We then wait for the query to Vendor Red to finish first, when we call p_red.join() , which takes 1000ms. During these 1000ms, the queries to Vendors Blue and Green, which take 300ms and 400ms respectively, have already finished. So, we don't have to wait on the vendors when we call p_green.join() and p_blue.join() . Overall, this approach takes a 1000ms, which is obviously better than the serial & synchronous approach. Vendor Query time Total time Red 1000 ms Green 300 ms Blue 400 ms 1000 ms But, this approach is still on resources. Each process takes separate memory to run. Each process also needs time to be setup. Depending on the machine, we may not have 3 processes to spare. And, in a real-world case, such as for our own Kayak-type website, we may have thousands of queries that need to be run parallely. We don't have a machine that has thousands of processors. And, even if we did, creating thousands of processes would have trememdous overhead which would negate any multiprocessing gains. We could use a worker pool of three processes that rotates through thousands of queries three at a time. This three-at-a-time parallelism would still take a long time to work through thousands of queries because only three queries would be active at a time. Alternatively, we could use threads (within the main process) to implement the parallelism. Threads share memory and can be started and ended much faster than processes. Obviously, in the default CPython, this would not be truly parallel because the Global Interpreter Lock only allows one thread to have access to the interpreter at one time. There are different Python implementations that do not have a GIL. IronPython is one such example. In a GIL-free python implementation, the threads may be able to behave truly parallely. Our toy example only needs three threads and would definitely benefit from a GIL-free implementation. However, our own Kayak-type website would require thousands of threads, which is more efficient than thousands of processes, but is still not efficient enough. Thousands of threads may not even be possible on a machine. We could use a worker pool of three threads that rotates through thousands of queries three at a time. As with processes, this three-at-a-time GIL-free parallelism would still take a long time to work through thousands of queries because only three queries would be active at a time.","title":"Parallel &amp; synchronous"},{"location":"suspendables/buying-a-plane-ticket/#there-is-room-for-improvement","text":"Servers have internal latencies and transferring data over the network takes time. We don't need to perform a lot of computation, we simply need to receive the price data. There is no inherent need to create threads or processes simply to handle the incoming data. Before the advent of asychronous programming, we were forced to create multiple threads or processes because there was nothing better available.","title":"There is room for improvement"},{"location":"suspendables/buying-a-plane-ticket/#not-parallel-asynchronous","text":"This approach uses a single thread within a single process. We don't have the overhead of creating new threads or processes. The magic here is that we made the get_price function suspendable. The pseudocode below has janky syntax. This is purposeful as we will explain in the next section on syntax . For now, we will ignore the syntax issues and focus on how asychronous programming can solve our problem even more efficiently than parallelism. Pseudocode suspendable function get_price ( vendor ) request = create_request ( vendor ) release control # suspension/control transfer point request . wait () print ( f 'Received price from the vendor { vendor } !' ) return request . result # Initiate all requests but don't wait for them to finish get_price ( red ) get_price ( green ) get_price ( blue ) # Resume suspended functions and wait for them to complete red_price = get_price ( red ) . wait () # Waits 1000ms green_price = get_price ( green ) . wait () # No wait; we've already waited 300ms blue_price = get_price ( blue ) . wait () # No wait; we've already waited 400ms min ([ red_price , green_price , blue_price ]) # Did you notice the janky syntax in this pseudocode? This is why we need # to answer the syntax question in the next few section. We call get_price three times, once for each of the three vendors. This sends a query to each of the three vendor websites but doesn't immediately wait for the queries to be answered. Once all three queries have been sent, the pseudocode then waits for the queries to be answered in a particular, distinguished order -- it waits for red to finish, then green to finish, and then red to finish. Similar to the parallel & synchronous approach, we only have to wait a 1000ms in all. Vendor Query time Total time Red 1000 ms Green 300 ms Blue 400 ms 1000 ms Asynchronous approach is just as fast as the parallel & synchronous approach. But, asynchronous approach can handle thousands of queries within the same thread and the same process. Even if we had a thousand queries, we could start all of the queries nearly simultaneously without waiting for them to finish. Finally, let's not forget that we could still use process-based parallelism along side asychronous programming.","title":"Not parallel &amp; asynchronous"},{"location":"suspendables/buying-a-plane-ticket/#not-just-theoretical","text":"Nginx vs Apache provides a real-world, industrial-strength example where asynchronous programming outperforms parallelism via multithreading.","title":"Not just theoretical"},{"location":"suspendables/buying-a-plane-ticket/#summary","text":"Approach Time Processes Threads Limited by Serial & Synchronous 1700 ms 1 1 - Parallel & Synchronous (Processes) 1000 ms 1 + 3 1 / process processor count Parallel & Synchronous (Threads, GIL-free) 1000 ms 1 1 + 3 processor count Asychronous 1000 ms 1 1 network bandwidth","title":"Summary"},{"location":"suspendables/control/","text":"Control \u00b6 Control Who gets the control when a suspendable entity suspends execution ? In our opinion, this key question is often avoided by most other tutorials, which makes learning unncessarily difficult. We alluded to this in the beginning . In this course, we use new terminology to answer this question. Specifically, we subcategorize suspendables on the basis of control flow: Explicit Control Transfer Suspendables Implicit Control Transfer Suspendables We use python-like pseudocode instead of real python code throughout this page. We cannot use real python code yet because we haven't answered the question of syntax . Explicit Control Transfer Suspendables \u00b6 Let's re-visit our Salad & Mashed Potatoes example from before. We previously noted that making mashed_potatoes a suspendable recipe would be more efficient because we can execute salad while the potatoes are boiling. In order to do so, we need to break up boil_potatoes into three pieces: boil_potatoes start_boiling_potatoes Put the potatoes and water in a saucepan and set the auto shutoff timer for 15 minutes release control while the potatoes are boiling finish_boiling_potatoes Drain the hot water from the saucepan and extract boiled potatoes We can write our code in one of two ways as shown below. Example 1 Example 2 function salad chop_lettuce_into_the_bowl() chop_tomato_into_the_bowl() chop_cucumber_into_the_bowl() suspendable function mashed_potatoes peel_potatoes() cut_potatoes() start_boiling_potatoes(minutes=15, auto_shutoff= true ) release control # to the caller finish_boiling_potatoes() mash_potatoes() stir_potatoes_with_butter() function main mashed_potatoes() salad() mashed_potatoes() # resume suspended run main() function salad chop_lettuce_into_the_bowl() chop_tomato_into_the_bowl() chop_cucumber_into_the_bowl() suspendable function mashed_potatoes peel_potatoes() cut_potatoes() start_boiling_potatoes(minutes=15, auto_shutoff= true ) release control to salad() finish_boiling_potatoes() mash_potatoes() stir_potatoes_with_butter() function main mashed_potatoes() main() In Example 1, control is transferred from main to mashed_potatoes , which transfers the control back to main once the potatoes are set to boil. main then sends the control to salad which finishes its job and returns control back to main like any traditional function. main then calls mashed_potatoes once again to resume the suspended run 1 . In Example 2, control is transferred from main to mashed_potatoes , which then transfers the control to salad while the potatoes are boiling instead of returning control back to main . salad finishes its job and returns control back to its caller which happens to be mashed_potatoes . Finally, mashed_potatoes then finishes its job and transfers control back to main at the end. In both examples, the suspendable function transfers the control explicitly and deterministically from itself to another known function. In Example 1, during suspension, the control transfers from mashed_potatoes to its caller, main . In Example 2, the control transfers from mashed_potatoes to salad . In both of these examples, the programmer knows deterministically which line of the program would execute immediately after the control is released during suspension without having to run the code at all. The suspendable mashed_potatoes in both examples is an Explicit Control Transfer Suspendable. The idea of explicit control transfer is best understood in contrast to the implicit control transfer. Implicit Control Transfer Suspendables \u00b6 The Plane Ticket example is the perfect example to demonstrate the need for implicit control transfer suspendables. We previously discussed this classic example to show the benefit of asynchronous programming over serial and parallel programming. We will now use this classic example to demonstrate the need for implicit control transfer suspendables as well. The pseudocode we prevoisly saw is simply the naive implementation shown below. We will now discuss the drawbacks of the naive implementation and then provide an improved implementation. As we discussed before, the pseudocode purposefully has janky syntax, as we will explain in the next section on syntax . For now, we will ignore the syntax issues and focus on control transfer. Naive implementation Improved implementation Pseudocode suspendable function get_price ( vendor ) request = create_request ( vendor ) release control request . wait () print ( f 'Received price from the vendor { vendor } !' ) return request . result # Initiate all requests get_price ( red ) get_price ( green ) get_price ( blue ) # Resume suspended functions and wait for them to complete red_price = get_price ( red ) . wait () green_price = get_price ( green ) . wait () blue_price = get_price ( blue ) . wait () # Find the best price # Could we have started this computation with just two prices? min ([ red_price , green_price , blue_price ]) # Did you notice the janky syntax in this pseudocode? This is why we need # to answer the syntax question in the next section. Pseudocode suspendable function get_price ( vendor ) request = create_request ( vendor ) while request . result is None : release control print ( f 'Received price from the vendor { vendor } !' ) return request . result # Suspend-resume loop until all requests are done waiting = [ red , green , blue ] best_price = infinity while waiting : # Check to see if the query has finished vendor = waiting . pop () price = get_price ( vendor ) if price is None : # If query didn't finish yet, add it to the waiting list again. # We'll check on it again. waiting . append ( vendor ) else : # If query returned, start comparing. No need to wait for other # queries to finish. if price < best_price : best_price = price # Did you notice the janky syntax in this pseudocode? This is why we need # to answer the syntax question in the next section. There is still room for improvement \u00b6 Even though our naive implementation of the asychronous approach was much better than the serial and parallel approaches, the naive implementation is still inefficient. We need to perform a few comparison operations in order to compute the minimum of three numbers. These comparison operations also cost time. In the naive approach, we waited for all three asynchronous queries to finish before we computed the minimum price. This idle waiting is wasteful. Just after the 400ms mark, we have the prices from Vendors Green and Blue but we don't have the price from Vendor Red. We needed to wait another 600ms before we obtained the price from Vendor Red. We could have computed the smaller of the blue and green prices during that 600ms. However, the naive approach waits for the queries to finish in a very particular, distinguished order - it waits for red, then green, then blue. This forces us to idly wait during that 600ms period. If we re-order the vendors to wait for green first, then blue, and then red, we may be able to use that 600ms otherwise idle time to compare the blue and green prices. But, even re-ordering the queries is not a practical solution because we may not know the vendor latencies pre-emptively. The benefit of utilizing the idle time to perform comparisons seems overkill for our toy example comprising of only three queries. But, imagine the real-world case of our own Kayak-type website. We will to perform thousands of comparisons among thousands of prices in order to compute the mimimum price. It would be noticelably slow to perform the thousands of comparisons only after all the queries have finished. Improved implementation \u00b6 The main difference between the naive and the improved implementation is that the improved implementation adds a while loop. Improved implementation does not wait for a query to complete. The while loop checks (but doesn't wait) to see if a query has completed. If it has completed, the loop updates the current minimum price. If the query has not yet completed, the loop puts back the query in the waiting list to be checked again at a later time. The while loop runs really fast compared to the queries. Therefore, roughly around 300ms mark, the loop will discover that the query to the Vendor Green is finished and the loop will remove Vendor Green from the waiting list. Then roughly, at 400ms mark, the loop will remove Vendor Blue from the waiting list and compare the prices from the Vendors Green and Blue to compute the current minmum price. This comparison between the prices from the Vendors Green and Blue happens much before the query to Vendor Red finishes. Finally, at 1000ms, the loop will have gone through all the queries and will have computed the bets price. This is too common a scenario \u00b6 Looping through events is an extremely common scenario and for the same reason -- in real life, we cannot know, in an a priori manner, the chronological order of task completion. Therefore, we need to loop over the tasks to determine which task needs to be assigned to the processor. This loop is called the event loop . The pseudocode while loop we just disucssed is called a rudimentary form of the industrial-strength event loop that you would find in asynchronous programming packages such as asyncio or uvloop . Every programmer can write their own custom loop; after all, we just did so in pseudocode. So, why have the programming language provide whole machinery to run suspendable tasks in an event loop? Because real-world scenarios are more complicated. For example, a suspendable function could call another suspendable function, which could call another suspendable function and so on. An event loop needs to keep track of all these suspendable functions properly and give all of them some processing time. Since this scenario is too common, Python 3 provides, as a first class feature, the syntax and packages needed to run an event loop without having to write a custom event loop yourself. That said, third party event loops are available, such as uvloop and trio . And, of course, you can write your own custom loop from scratch as demonstrated in a live coding session at PyCon 2015 by David Beazley 2 . How does this relate to Implicit Control Transfer Suspendables? \u00b6 The suspendable functions in our improved implementation transfer control to the while loop. The event loop can only coordinate the work if the control is transferred from the suspendable function to the event loop. If you transfer the control to some other entity besides the event loop, then the event loop cannot coordinate the work properly. But, the event loop typically doesn't really do much work for itself. Its main job is to transfer the control from one suspendable function to another. We could argue that the event loop facilitates control transfer between suspendable functions. In other words, the control is implicitly transferred between suspendable functions via the event loop. In real python code, the event loop is nearly invisible to the end user. As a result, the end user perceives the control being transferred between their user-written suspendable functions. It often not be possible to pre-emptively tell which suspendable function (among a whole list of suspendable functions waiting for resumption) will finish first. Thus, it's not possible to deterministically say which suspendable function will transfer the control to which other suspendable function, via the event loop. In other words, the control is transferred non-deterministically amongst the suspendable functions. Finally, uou could reasonably argue that the pseudocode in the improved implementation actually uses explicit control transfer. This is correct! Implicit control transfer mechanism is indeed built upon the explicit control transfer mechanism with the event loop being the invisble control tranfer coordinator. Explicit v. Implicit Control Transfer \u00b6 Some asynchronous tasks, such as the Salad & Mashed Potatoes example, do not benefit for an event loop 3 . There is no need to force such functions to run within an event loop. Some asynchronous tasks, such as the Plane Ticket example, almost always require an event loop to run efficiently. It is inefficient to not run these functions within an event loop 4 . One unified syntax for both explicit & implicit control tranfer? \u00b6 While there is a natural distinction between the type of suspendable functions that require an event loop and those who don't, there appears to be no reason why the syntax for explicit and implicit control transfer suspendables should be different. It is somewhat reasonable to expect that a programming language provide only one type of suspendable function with the same set of reserved keywords for both explicit and implicit control transfer. Perhaps, a suspendable function's control transfer can be made explicit or implicit automatically depending on whether or not it interacts with an event loop? This happens to not be the case with python, as of writing this course. The following table describes how python 3.8.5+ bifurcates the concept of suspendables into two specialized entities, each with its own set of keywords. Item Pseudocode (Explicit & Implicit) Python (Explicit) Python (Implicit) Name Suspendable Generator Coroutine Requires event loop Yes & No No Yes Function definer function def def Suspendable modifier suspendable - async Control transfer to caller release control yield - Control transfer to another release control to yield from await In python, explicit control transfer suspendables are implemented as generators and implicit control transfer suspendables are implemented as coroutines 5 . The reason for this bifurcation is complicated involving syntactical, historical, and design considerations. Just after PEP 342 , the same yield from syntax was used for both (explicit) generators and (implicit) coroutines. But, using the same syntax for both generators and coroutines created problems and confusion, as mentioned in PEP 492 . PEP 492 finally separated coroutines from generators. We will discuss some of these syntactical, historical, and design considerations later in the course. One weird artifact of this bifurcation is that python may allow a suspendable to be both explicit and implicit at the same time. This is what python calls asynchronous generators , as described in this bug report and discussed in PEP 492 . We will discuss this illumintaing oddity later in the course. Suspension point (aka Control transfer point) \u00b6 A suspendable function cannot willy-nilly suspend execution (and allow control transfer) anywhere. The control can only be transferred away from the suspendable function at the designated suspension points aka control transfer points . In our pseudocode, for both explicit and implicit control transfer suspendables, this suspension point is designated by the special keywords release control . When we move from pseudocode to real python code, we will see actual python keywords that indicate the suspension points. We're not done yet \u00b6 Before we begin discussing python generators and coroutines, we need to solve the problem of defining unambiguous syntax for suspendables. Footnotes \u00b6 Wary readers may already have noticed the ambiguity in the second call to mashed_potatoes . How would we differentiate between a resumption of a previously suspended run and a second independent run of a suspendable function? This is exactly why we had to use pseudocode for our examples. We tackle this question of unambiguous syntax and semantics next . \u21a9 David Beazley's live coding of an event loop is highly recommended in spite of the following caveats. Please be aware that this video uses an alpha version of Python 3.5 and the old yield from syntax intended for soon to be deprecated generator-based coroutines. Generator-based coroutines are an enormous source of confusion as discussed in the beginning of this course and this course does not describe them for this reason. Further, PEP 492 makes it illegal to have a yield or yield from within a native coroutine. See this footnote to go one step further down into the deep hole. \u21a9 A memory-efficient, boundless iterator (such as Python 3's range ) is a common real-world example of a suspendable function that does not benefit from an event loop. \u21a9 Unless it's for educational purposes . \u21a9 We are purposefully ignoring the existence of generator-based coroutines. See Footnote 2 on this page. \u21a9","title":"Control"},{"location":"suspendables/control/#control","text":"Control Who gets the control when a suspendable entity suspends execution ? In our opinion, this key question is often avoided by most other tutorials, which makes learning unncessarily difficult. We alluded to this in the beginning . In this course, we use new terminology to answer this question. Specifically, we subcategorize suspendables on the basis of control flow: Explicit Control Transfer Suspendables Implicit Control Transfer Suspendables We use python-like pseudocode instead of real python code throughout this page. We cannot use real python code yet because we haven't answered the question of syntax .","title":"Control"},{"location":"suspendables/control/#explicit-control-transfer-suspendables","text":"Let's re-visit our Salad & Mashed Potatoes example from before. We previously noted that making mashed_potatoes a suspendable recipe would be more efficient because we can execute salad while the potatoes are boiling. In order to do so, we need to break up boil_potatoes into three pieces: boil_potatoes start_boiling_potatoes Put the potatoes and water in a saucepan and set the auto shutoff timer for 15 minutes release control while the potatoes are boiling finish_boiling_potatoes Drain the hot water from the saucepan and extract boiled potatoes We can write our code in one of two ways as shown below. Example 1 Example 2 function salad chop_lettuce_into_the_bowl() chop_tomato_into_the_bowl() chop_cucumber_into_the_bowl() suspendable function mashed_potatoes peel_potatoes() cut_potatoes() start_boiling_potatoes(minutes=15, auto_shutoff= true ) release control # to the caller finish_boiling_potatoes() mash_potatoes() stir_potatoes_with_butter() function main mashed_potatoes() salad() mashed_potatoes() # resume suspended run main() function salad chop_lettuce_into_the_bowl() chop_tomato_into_the_bowl() chop_cucumber_into_the_bowl() suspendable function mashed_potatoes peel_potatoes() cut_potatoes() start_boiling_potatoes(minutes=15, auto_shutoff= true ) release control to salad() finish_boiling_potatoes() mash_potatoes() stir_potatoes_with_butter() function main mashed_potatoes() main() In Example 1, control is transferred from main to mashed_potatoes , which transfers the control back to main once the potatoes are set to boil. main then sends the control to salad which finishes its job and returns control back to main like any traditional function. main then calls mashed_potatoes once again to resume the suspended run 1 . In Example 2, control is transferred from main to mashed_potatoes , which then transfers the control to salad while the potatoes are boiling instead of returning control back to main . salad finishes its job and returns control back to its caller which happens to be mashed_potatoes . Finally, mashed_potatoes then finishes its job and transfers control back to main at the end. In both examples, the suspendable function transfers the control explicitly and deterministically from itself to another known function. In Example 1, during suspension, the control transfers from mashed_potatoes to its caller, main . In Example 2, the control transfers from mashed_potatoes to salad . In both of these examples, the programmer knows deterministically which line of the program would execute immediately after the control is released during suspension without having to run the code at all. The suspendable mashed_potatoes in both examples is an Explicit Control Transfer Suspendable. The idea of explicit control transfer is best understood in contrast to the implicit control transfer.","title":"Explicit Control Transfer Suspendables"},{"location":"suspendables/control/#implicit-control-transfer-suspendables","text":"The Plane Ticket example is the perfect example to demonstrate the need for implicit control transfer suspendables. We previously discussed this classic example to show the benefit of asynchronous programming over serial and parallel programming. We will now use this classic example to demonstrate the need for implicit control transfer suspendables as well. The pseudocode we prevoisly saw is simply the naive implementation shown below. We will now discuss the drawbacks of the naive implementation and then provide an improved implementation. As we discussed before, the pseudocode purposefully has janky syntax, as we will explain in the next section on syntax . For now, we will ignore the syntax issues and focus on control transfer. Naive implementation Improved implementation Pseudocode suspendable function get_price ( vendor ) request = create_request ( vendor ) release control request . wait () print ( f 'Received price from the vendor { vendor } !' ) return request . result # Initiate all requests get_price ( red ) get_price ( green ) get_price ( blue ) # Resume suspended functions and wait for them to complete red_price = get_price ( red ) . wait () green_price = get_price ( green ) . wait () blue_price = get_price ( blue ) . wait () # Find the best price # Could we have started this computation with just two prices? min ([ red_price , green_price , blue_price ]) # Did you notice the janky syntax in this pseudocode? This is why we need # to answer the syntax question in the next section. Pseudocode suspendable function get_price ( vendor ) request = create_request ( vendor ) while request . result is None : release control print ( f 'Received price from the vendor { vendor } !' ) return request . result # Suspend-resume loop until all requests are done waiting = [ red , green , blue ] best_price = infinity while waiting : # Check to see if the query has finished vendor = waiting . pop () price = get_price ( vendor ) if price is None : # If query didn't finish yet, add it to the waiting list again. # We'll check on it again. waiting . append ( vendor ) else : # If query returned, start comparing. No need to wait for other # queries to finish. if price < best_price : best_price = price # Did you notice the janky syntax in this pseudocode? This is why we need # to answer the syntax question in the next section.","title":"Implicit Control Transfer Suspendables"},{"location":"suspendables/control/#there-is-still-room-for-improvement","text":"Even though our naive implementation of the asychronous approach was much better than the serial and parallel approaches, the naive implementation is still inefficient. We need to perform a few comparison operations in order to compute the minimum of three numbers. These comparison operations also cost time. In the naive approach, we waited for all three asynchronous queries to finish before we computed the minimum price. This idle waiting is wasteful. Just after the 400ms mark, we have the prices from Vendors Green and Blue but we don't have the price from Vendor Red. We needed to wait another 600ms before we obtained the price from Vendor Red. We could have computed the smaller of the blue and green prices during that 600ms. However, the naive approach waits for the queries to finish in a very particular, distinguished order - it waits for red, then green, then blue. This forces us to idly wait during that 600ms period. If we re-order the vendors to wait for green first, then blue, and then red, we may be able to use that 600ms otherwise idle time to compare the blue and green prices. But, even re-ordering the queries is not a practical solution because we may not know the vendor latencies pre-emptively. The benefit of utilizing the idle time to perform comparisons seems overkill for our toy example comprising of only three queries. But, imagine the real-world case of our own Kayak-type website. We will to perform thousands of comparisons among thousands of prices in order to compute the mimimum price. It would be noticelably slow to perform the thousands of comparisons only after all the queries have finished.","title":"There is still room for improvement"},{"location":"suspendables/control/#improved-implementation","text":"The main difference between the naive and the improved implementation is that the improved implementation adds a while loop. Improved implementation does not wait for a query to complete. The while loop checks (but doesn't wait) to see if a query has completed. If it has completed, the loop updates the current minimum price. If the query has not yet completed, the loop puts back the query in the waiting list to be checked again at a later time. The while loop runs really fast compared to the queries. Therefore, roughly around 300ms mark, the loop will discover that the query to the Vendor Green is finished and the loop will remove Vendor Green from the waiting list. Then roughly, at 400ms mark, the loop will remove Vendor Blue from the waiting list and compare the prices from the Vendors Green and Blue to compute the current minmum price. This comparison between the prices from the Vendors Green and Blue happens much before the query to Vendor Red finishes. Finally, at 1000ms, the loop will have gone through all the queries and will have computed the bets price.","title":"Improved implementation"},{"location":"suspendables/control/#this-is-too-common-a-scenario","text":"Looping through events is an extremely common scenario and for the same reason -- in real life, we cannot know, in an a priori manner, the chronological order of task completion. Therefore, we need to loop over the tasks to determine which task needs to be assigned to the processor. This loop is called the event loop . The pseudocode while loop we just disucssed is called a rudimentary form of the industrial-strength event loop that you would find in asynchronous programming packages such as asyncio or uvloop . Every programmer can write their own custom loop; after all, we just did so in pseudocode. So, why have the programming language provide whole machinery to run suspendable tasks in an event loop? Because real-world scenarios are more complicated. For example, a suspendable function could call another suspendable function, which could call another suspendable function and so on. An event loop needs to keep track of all these suspendable functions properly and give all of them some processing time. Since this scenario is too common, Python 3 provides, as a first class feature, the syntax and packages needed to run an event loop without having to write a custom event loop yourself. That said, third party event loops are available, such as uvloop and trio . And, of course, you can write your own custom loop from scratch as demonstrated in a live coding session at PyCon 2015 by David Beazley 2 .","title":"This is too common a scenario"},{"location":"suspendables/control/#how-does-this-relate-to-implicit-control-transfer-suspendables","text":"The suspendable functions in our improved implementation transfer control to the while loop. The event loop can only coordinate the work if the control is transferred from the suspendable function to the event loop. If you transfer the control to some other entity besides the event loop, then the event loop cannot coordinate the work properly. But, the event loop typically doesn't really do much work for itself. Its main job is to transfer the control from one suspendable function to another. We could argue that the event loop facilitates control transfer between suspendable functions. In other words, the control is implicitly transferred between suspendable functions via the event loop. In real python code, the event loop is nearly invisible to the end user. As a result, the end user perceives the control being transferred between their user-written suspendable functions. It often not be possible to pre-emptively tell which suspendable function (among a whole list of suspendable functions waiting for resumption) will finish first. Thus, it's not possible to deterministically say which suspendable function will transfer the control to which other suspendable function, via the event loop. In other words, the control is transferred non-deterministically amongst the suspendable functions. Finally, uou could reasonably argue that the pseudocode in the improved implementation actually uses explicit control transfer. This is correct! Implicit control transfer mechanism is indeed built upon the explicit control transfer mechanism with the event loop being the invisble control tranfer coordinator.","title":"How does this relate to Implicit Control Transfer Suspendables?"},{"location":"suspendables/control/#explicit-v-implicit-control-transfer","text":"Some asynchronous tasks, such as the Salad & Mashed Potatoes example, do not benefit for an event loop 3 . There is no need to force such functions to run within an event loop. Some asynchronous tasks, such as the Plane Ticket example, almost always require an event loop to run efficiently. It is inefficient to not run these functions within an event loop 4 .","title":"Explicit v. Implicit Control Transfer"},{"location":"suspendables/control/#one-unified-syntax-for-both-explicit-implicit-control-tranfer","text":"While there is a natural distinction between the type of suspendable functions that require an event loop and those who don't, there appears to be no reason why the syntax for explicit and implicit control transfer suspendables should be different. It is somewhat reasonable to expect that a programming language provide only one type of suspendable function with the same set of reserved keywords for both explicit and implicit control transfer. Perhaps, a suspendable function's control transfer can be made explicit or implicit automatically depending on whether or not it interacts with an event loop? This happens to not be the case with python, as of writing this course. The following table describes how python 3.8.5+ bifurcates the concept of suspendables into two specialized entities, each with its own set of keywords. Item Pseudocode (Explicit & Implicit) Python (Explicit) Python (Implicit) Name Suspendable Generator Coroutine Requires event loop Yes & No No Yes Function definer function def def Suspendable modifier suspendable - async Control transfer to caller release control yield - Control transfer to another release control to yield from await In python, explicit control transfer suspendables are implemented as generators and implicit control transfer suspendables are implemented as coroutines 5 . The reason for this bifurcation is complicated involving syntactical, historical, and design considerations. Just after PEP 342 , the same yield from syntax was used for both (explicit) generators and (implicit) coroutines. But, using the same syntax for both generators and coroutines created problems and confusion, as mentioned in PEP 492 . PEP 492 finally separated coroutines from generators. We will discuss some of these syntactical, historical, and design considerations later in the course. One weird artifact of this bifurcation is that python may allow a suspendable to be both explicit and implicit at the same time. This is what python calls asynchronous generators , as described in this bug report and discussed in PEP 492 . We will discuss this illumintaing oddity later in the course.","title":"One unified syntax for both explicit &amp; implicit control tranfer?"},{"location":"suspendables/control/#suspension-point-aka-control-transfer-point","text":"A suspendable function cannot willy-nilly suspend execution (and allow control transfer) anywhere. The control can only be transferred away from the suspendable function at the designated suspension points aka control transfer points . In our pseudocode, for both explicit and implicit control transfer suspendables, this suspension point is designated by the special keywords release control . When we move from pseudocode to real python code, we will see actual python keywords that indicate the suspension points.","title":"Suspension point (aka Control transfer point)"},{"location":"suspendables/control/#were-not-done-yet","text":"Before we begin discussing python generators and coroutines, we need to solve the problem of defining unambiguous syntax for suspendables.","title":"We're not done yet"},{"location":"suspendables/control/#footnotes","text":"Wary readers may already have noticed the ambiguity in the second call to mashed_potatoes . How would we differentiate between a resumption of a previously suspended run and a second independent run of a suspendable function? This is exactly why we had to use pseudocode for our examples. We tackle this question of unambiguous syntax and semantics next . \u21a9 David Beazley's live coding of an event loop is highly recommended in spite of the following caveats. Please be aware that this video uses an alpha version of Python 3.5 and the old yield from syntax intended for soon to be deprecated generator-based coroutines. Generator-based coroutines are an enormous source of confusion as discussed in the beginning of this course and this course does not describe them for this reason. Further, PEP 492 makes it illegal to have a yield or yield from within a native coroutine. See this footnote to go one step further down into the deep hole. \u21a9 A memory-efficient, boundless iterator (such as Python 3's range ) is a common real-world example of a suspendable function that does not benefit from an event loop. \u21a9 Unless it's for educational purposes . \u21a9 We are purposefully ignoring the existence of generator-based coroutines. See Footnote 2 on this page. \u21a9","title":"Footnotes"},{"location":"suspendables/cooking-is-like-programming/","text":"Cooking is like programming \u00b6 It is easier to understand async python programming if we temporarily forget about the structured control flow as it exists in contemporary programming. This is easier said than done. Most of us are so well-versed with these common control flow constructs (such as functions ) that it is difficult for us to completely let go of these ideas. So, let's use a trick! Cooking is surprisingly similar to programming. We will use cooking as an example to understand the need for a suspendable , which we will then define on the next page. Bear Crumpet \u00b6 Let's say we invent a completely new baked good and we name it bear crumpet . Our first ten attempts to make an bear crumpet required a lot of experimentation \u2014 we needed to adjust the amount of ingredients and we had to play around with the oven temperature and timing. After the first ten attempts, we perfected our invention \u2014 it's 50% tastier than a regular crumpet and 75% more awesome than a bear claw ! We need to save the results from our experimentation so we can get the perfect bear crumpet every time without having to redo the experiments. What we need is an ordered sequence of instructions , i.e. a recipe describing how to make an bear crumpet . A cooking recipe can be thought of as a function in programming. But, we purposefully, choose the word recipe instead of a function because recipe does not come with a predefined, hard-to-disassociate connotation that comes with function . Let's make two other food items using recipes \u2014 salad and mashed potatoes. Salad \u00b6 The following pseudocode represents a recipe for a very simple salad: recipe salad chop_lettuce_into_the_bowl() chop_tomato_into_the_bowl() chop_cucumber_into_the_bowl() Let's say a single chef executes this recipe to make a salad. There are three steps to this simple recipe: Chop lettuce Chop tomato Chop cucumber For a salad, the order of the steps does not matter. We could, just as easily, have chopped tomato first, then lettuce, and then cucumber. Here is an alternative but somewhat crazier recipe for the same salad: Start chopping lettuce but stop midway Start chopping cucumber but stop midway Finish chopping lettuce Finish chopping cucumber Chop tomato Not only does the order of the three steps not matter, we can even interleave the steps and still have a salad 1 . Mashed Potatoes \u00b6 Let's consider something more complex than a salad. The following pseudocode is a simple recipe for mashed potatoes: recipe mashed_potatoes peel_potatoes() cut_potatoes() boil_potatoes(minutes=15, auto_shutoff= true ) # Could we do other work here? mash_potatoes() stir_potatoes_with_butter() As before, let's assume that a single person executes this recipe. The first two steps are simple enough \u2014 peel and cut potatoes. The third step, boiling the potatoes, is where the complexity arises. Unlike the salad recipe, the order of steps is important for mashed potatoes. We must cut and peel the potatoes before we boil them 2 and we need to finish boiling the potatoes before we can mash the boiled potatoes. It takes 15 minutes to boil the potatoes during which the chef is idle but cannot begin mashing the mashing the potatoes. The chef must wait until the potatoes are boiled, which is a waste of time 3 . Salad & Mashed Potatoes \u00b6 Now, let's consider the scenario in which a single chef has to make the salad as well as the mashed potatoes. The chef can work serially \u2014 make the salad first and then make the mashed potatoes, but this is not an efficient use of time. The chef can save some time 4 by interleaving the steps like this: Peel potatoes Cut potatoes Set the potatoes to boil Temporarily suspend working on mashed potatoes Make the salad Resume making mashed potatoes If we suspend the execution of mashed_potatoes just after starting the boiling step, we can use that time to execute salad instead of waiting by idly for the potatoes to boil. Thus, we can be more efficient with our time if we make mashed_potatoes a suspendable recipe. The same motivation applies to functions in programming. Footnotes \u00b6 The make_salad example is, in fact, an ideal use-case for threads. Multithreading was available before multicore processors were available. The primary motivation for multiple threads back then was to interleave unrelated tasks on the single CPU core. See Thinking Outside the Synchronisation Quadrant - Kevlin Henney - YouTube . \u21a9 It is well-known that boiling uncut and unpeeled potatoes makes for a poorer recipe. \u21a9 Think of the chef as a process that is forced to stay idle while waiting for some computation to finish. \u21a9 This is how Samwise Gamgee does it. \u21a9","title":"Cooking is like programming"},{"location":"suspendables/cooking-is-like-programming/#cooking-is-like-programming","text":"It is easier to understand async python programming if we temporarily forget about the structured control flow as it exists in contemporary programming. This is easier said than done. Most of us are so well-versed with these common control flow constructs (such as functions ) that it is difficult for us to completely let go of these ideas. So, let's use a trick! Cooking is surprisingly similar to programming. We will use cooking as an example to understand the need for a suspendable , which we will then define on the next page.","title":"Cooking is like programming"},{"location":"suspendables/cooking-is-like-programming/#bear-crumpet","text":"Let's say we invent a completely new baked good and we name it bear crumpet . Our first ten attempts to make an bear crumpet required a lot of experimentation \u2014 we needed to adjust the amount of ingredients and we had to play around with the oven temperature and timing. After the first ten attempts, we perfected our invention \u2014 it's 50% tastier than a regular crumpet and 75% more awesome than a bear claw ! We need to save the results from our experimentation so we can get the perfect bear crumpet every time without having to redo the experiments. What we need is an ordered sequence of instructions , i.e. a recipe describing how to make an bear crumpet . A cooking recipe can be thought of as a function in programming. But, we purposefully, choose the word recipe instead of a function because recipe does not come with a predefined, hard-to-disassociate connotation that comes with function . Let's make two other food items using recipes \u2014 salad and mashed potatoes.","title":"Bear Crumpet"},{"location":"suspendables/cooking-is-like-programming/#salad","text":"The following pseudocode represents a recipe for a very simple salad: recipe salad chop_lettuce_into_the_bowl() chop_tomato_into_the_bowl() chop_cucumber_into_the_bowl() Let's say a single chef executes this recipe to make a salad. There are three steps to this simple recipe: Chop lettuce Chop tomato Chop cucumber For a salad, the order of the steps does not matter. We could, just as easily, have chopped tomato first, then lettuce, and then cucumber. Here is an alternative but somewhat crazier recipe for the same salad: Start chopping lettuce but stop midway Start chopping cucumber but stop midway Finish chopping lettuce Finish chopping cucumber Chop tomato Not only does the order of the three steps not matter, we can even interleave the steps and still have a salad 1 .","title":"Salad"},{"location":"suspendables/cooking-is-like-programming/#mashed-potatoes","text":"Let's consider something more complex than a salad. The following pseudocode is a simple recipe for mashed potatoes: recipe mashed_potatoes peel_potatoes() cut_potatoes() boil_potatoes(minutes=15, auto_shutoff= true ) # Could we do other work here? mash_potatoes() stir_potatoes_with_butter() As before, let's assume that a single person executes this recipe. The first two steps are simple enough \u2014 peel and cut potatoes. The third step, boiling the potatoes, is where the complexity arises. Unlike the salad recipe, the order of steps is important for mashed potatoes. We must cut and peel the potatoes before we boil them 2 and we need to finish boiling the potatoes before we can mash the boiled potatoes. It takes 15 minutes to boil the potatoes during which the chef is idle but cannot begin mashing the mashing the potatoes. The chef must wait until the potatoes are boiled, which is a waste of time 3 .","title":"Mashed Potatoes"},{"location":"suspendables/cooking-is-like-programming/#salad-mashed-potatoes","text":"Now, let's consider the scenario in which a single chef has to make the salad as well as the mashed potatoes. The chef can work serially \u2014 make the salad first and then make the mashed potatoes, but this is not an efficient use of time. The chef can save some time 4 by interleaving the steps like this: Peel potatoes Cut potatoes Set the potatoes to boil Temporarily suspend working on mashed potatoes Make the salad Resume making mashed potatoes If we suspend the execution of mashed_potatoes just after starting the boiling step, we can use that time to execute salad instead of waiting by idly for the potatoes to boil. Thus, we can be more efficient with our time if we make mashed_potatoes a suspendable recipe. The same motivation applies to functions in programming.","title":"Salad &amp; Mashed Potatoes"},{"location":"suspendables/cooking-is-like-programming/#footnotes","text":"The make_salad example is, in fact, an ideal use-case for threads. Multithreading was available before multicore processors were available. The primary motivation for multiple threads back then was to interleave unrelated tasks on the single CPU core. See Thinking Outside the Synchronisation Quadrant - Kevlin Henney - YouTube . \u21a9 It is well-known that boiling uncut and unpeeled potatoes makes for a poorer recipe. \u21a9 Think of the chef as a process that is forced to stay idle while waiting for some computation to finish. \u21a9 This is how Samwise Gamgee does it. \u21a9","title":"Footnotes"},{"location":"suspendables/review/","text":"Review \u00b6 Alternative models of async programming \u00b6 There are many models for asynchronous programming. The following table is an non-exhaustive list of some of these models. Model Language Comments Callbacks Javascript Very common in Javascript Python Callbacks can be used in python, even if less popular than suspendables Greenlets Python Gevent uses greenlets Goroutines Go Run a function synchronously or asynchronously as a goroutine Suspendables Javascript Javascript inspired async / await keywords in python Kotlin Clean & modern implementation of suspendables Python Incrementally added to Python 3 since 2001 Even though python itself has at least three competing models, namely callbacks, greenlets, and suspendables, this course only describes suspendables in detail. This is because at the time of writing this course, suspendables are the newest, trendiest, and arguably (contentiously) the best model of asynchronous programming in python, so much so that the phrase asynchronous programming often defaults to mean suspendables . Python is an older programming language which initially did not have native support for asynchronous programming. This support was incrementally added later and as a result the syntax for suspendables may not be as clean as in some of the newer languages. For example, Kotlin has a dramatically clearer description and terminology including the explicit use of the the word suspendable, suspendion point, and continuation. They even have a suspending lambda. Go provides its namesake goroutine . In Go, you can define a function and decide to execute it synchronously like usual (therebey treating the function as a simple function) or calling the same function asynchronously within a goroutine (thereby treating the function as an extended function). All of this without requiring any special syntax in the definition of the function. Python from here on \u00b6 Before we move to discussing the exact details of asynchronous programming in python, let's review what we discussed until now. Suspendables by control transfer \u00b6 Based on how the control is transferred, suspendables can be categorized into Explicit Control Transfer Suspendables Implicit Control Transfer Suspendables Python provides generators as an implementation of an explicit control transfer suspendable and coroutines as an implementation of an implicit control transfer suspendable. Suspendable Type Python Implementation Explicit Control Transfer Generators Implicit Control Transfer Coroutines It may be argued, with some merit, that only coroutines qualify as a model of asynchronous programming and generators do not. However, you could add an event loop over generators to emulate a coroutine, as was done in our improved implementation as well as David Beazley's live coding . In any case, it is nearly impossible, if not immensely impractical, to discuss coroutines (which are uncontentiously a model of asynchronous programming) without discussing generators. Suspenables by syntax \u00b6 Since we prefer suspendables to have a functional form, suspendable functions cannot be implemented as simple functions. Both generators and coroutines are implemented as extended functions. Calling a generator or a coroutine does not execute the internal contents of the suspendable but instead returns an object that can be used to execute the contnts. In the rest of this course, we will study python's implementation of generators and coroutines, while discussing their specific design, syntax, and control flow. Suspendables by control transfer and by syntax \u00b6 Control transfer and syntax are orthogonal properties. Both (explicit) generators and (implicit) coroutines are extended functions.","title":"Review"},{"location":"suspendables/review/#review","text":"","title":"Review"},{"location":"suspendables/review/#alternative-models-of-async-programming","text":"There are many models for asynchronous programming. The following table is an non-exhaustive list of some of these models. Model Language Comments Callbacks Javascript Very common in Javascript Python Callbacks can be used in python, even if less popular than suspendables Greenlets Python Gevent uses greenlets Goroutines Go Run a function synchronously or asynchronously as a goroutine Suspendables Javascript Javascript inspired async / await keywords in python Kotlin Clean & modern implementation of suspendables Python Incrementally added to Python 3 since 2001 Even though python itself has at least three competing models, namely callbacks, greenlets, and suspendables, this course only describes suspendables in detail. This is because at the time of writing this course, suspendables are the newest, trendiest, and arguably (contentiously) the best model of asynchronous programming in python, so much so that the phrase asynchronous programming often defaults to mean suspendables . Python is an older programming language which initially did not have native support for asynchronous programming. This support was incrementally added later and as a result the syntax for suspendables may not be as clean as in some of the newer languages. For example, Kotlin has a dramatically clearer description and terminology including the explicit use of the the word suspendable, suspendion point, and continuation. They even have a suspending lambda. Go provides its namesake goroutine . In Go, you can define a function and decide to execute it synchronously like usual (therebey treating the function as a simple function) or calling the same function asynchronously within a goroutine (thereby treating the function as an extended function). All of this without requiring any special syntax in the definition of the function.","title":"Alternative models of async programming"},{"location":"suspendables/review/#python-from-here-on","text":"Before we move to discussing the exact details of asynchronous programming in python, let's review what we discussed until now.","title":"Python from here on"},{"location":"suspendables/review/#suspendables-by-control-transfer","text":"Based on how the control is transferred, suspendables can be categorized into Explicit Control Transfer Suspendables Implicit Control Transfer Suspendables Python provides generators as an implementation of an explicit control transfer suspendable and coroutines as an implementation of an implicit control transfer suspendable. Suspendable Type Python Implementation Explicit Control Transfer Generators Implicit Control Transfer Coroutines It may be argued, with some merit, that only coroutines qualify as a model of asynchronous programming and generators do not. However, you could add an event loop over generators to emulate a coroutine, as was done in our improved implementation as well as David Beazley's live coding . In any case, it is nearly impossible, if not immensely impractical, to discuss coroutines (which are uncontentiously a model of asynchronous programming) without discussing generators.","title":"Suspendables by control transfer"},{"location":"suspendables/review/#suspenables-by-syntax","text":"Since we prefer suspendables to have a functional form, suspendable functions cannot be implemented as simple functions. Both generators and coroutines are implemented as extended functions. Calling a generator or a coroutine does not execute the internal contents of the suspendable but instead returns an object that can be used to execute the contnts. In the rest of this course, we will study python's implementation of generators and coroutines, while discussing their specific design, syntax, and control flow.","title":"Suspenables by syntax"},{"location":"suspendables/review/#suspendables-by-control-transfer-and-by-syntax","text":"Control transfer and syntax are orthogonal properties. Both (explicit) generators and (implicit) coroutines are extended functions.","title":"Suspendables by control transfer and by syntax"},{"location":"suspendables/suspendables/","text":"Suspendables \u00b6 On the previous page, we made a cooking recipe suspendable. A cooking recipe is analogous to a python function and a suspendable recipe is analogous to suspendable function in python. This is where programming becomes more complex than cooking. A suspendable function requires a lot more design thought than a suspendable recipe . We will see in the next few pages that a suspendable function cannot be the same type of entity as a simple function . Let's not design our suspendable function just yet. Instead, let's think of an abstract python entity called suspendable or suspendable entity , which may or may not be related to a plain, vanilla python function. In other words, a suspendable entity could either be a python function, or a python class, or something else entirely. Suspendable (or Suspendable Entity) A python entity containing an ordered sequence of instructions that can suspend and resume execution while maintaining its state. This definition of a suspendable entity is purposefully vague and incomplete. It does not fully nail down the specification of the suspendable entity . This leaves us a lot of room for design. We can design many distinct entities that can satisfy the above definition. To phrase it yet another way, there can be many different implementations of a suspendable entity . Any implementation of a suspendable entity needs to answer the following questions. The rest of this chapter will try to answer these two questions. Control \u00b6 Who gets the control when a suspendable entity suspends execution ? Syntax \u00b6 What syntax is needed to correctly define a suspendable entity ?","title":"Suspendables"},{"location":"suspendables/suspendables/#suspendables","text":"On the previous page, we made a cooking recipe suspendable. A cooking recipe is analogous to a python function and a suspendable recipe is analogous to suspendable function in python. This is where programming becomes more complex than cooking. A suspendable function requires a lot more design thought than a suspendable recipe . We will see in the next few pages that a suspendable function cannot be the same type of entity as a simple function . Let's not design our suspendable function just yet. Instead, let's think of an abstract python entity called suspendable or suspendable entity , which may or may not be related to a plain, vanilla python function. In other words, a suspendable entity could either be a python function, or a python class, or something else entirely. Suspendable (or Suspendable Entity) A python entity containing an ordered sequence of instructions that can suspend and resume execution while maintaining its state. This definition of a suspendable entity is purposefully vague and incomplete. It does not fully nail down the specification of the suspendable entity . This leaves us a lot of room for design. We can design many distinct entities that can satisfy the above definition. To phrase it yet another way, there can be many different implementations of a suspendable entity . Any implementation of a suspendable entity needs to answer the following questions. The rest of this chapter will try to answer these two questions.","title":"Suspendables"},{"location":"suspendables/suspendables/#control","text":"Who gets the control when a suspendable entity suspends execution ?","title":"Control"},{"location":"suspendables/suspendables/#syntax","text":"What syntax is needed to correctly define a suspendable entity ?","title":"Syntax"},{"location":"suspendables/syntax/","text":"Syntax \u00b6 Syntax What syntax is needed to correctly define a suspendable entity ? We have previously noticed that the syntax we used was janky, even for pseudocode. Function \u00b6 Let's begin with a relevant albeit non-traditional definition of a function. Function A function is a packaged unit of code that has at least two stages: 1. defining stage 2. calling stage These two stages are so trivial that one may wonder why are we even discussing it. Hopefully, the necessity of this discussion will soon become clear. Defining stage \u00b6 A function may be defined by executing code such as the following. Python def square ( x ): x_squared = x ** 2 return x Executing the above code doesn't actually execute the contents of square 1 . In fact, when we execute the above code, we don't even know which value of x needs to be squared. Thus, it would not even make sense to execute the contents of square while defining it. Calling stage \u00b6 The function square can be called like so: Python square ( 2 ) # 4 Calling a function means executing a code snippet of the form function_name(optional_args) . It just so happens that calling square executes the contents of square . This may sound torturedly pedantic. After all, what else could we possibly mean by calling a function ? It turns out that there may be situations where calling an entity may not necessarily execute the contents of the entity. Call \u2260 Execute, necessarily \u00b6 Let's broaden our notion of what it means to call an entity . In python, functions are not the only callable entities. Calling a class \u00b6 Let's consider the following simple class. Python class HelloWorld (): def __init__ ( self , data ): self . data = data def __repr__ ( self ): return f ' { self . __class__ . __name__ } ( { self . data } )' def __call__ ( self ): return self . data def set ( self , new_data ): self . data = new_data We can call the HelloWorld class just like we could call a simple function. Python y = HelloWorld ( 1 ) Calling HelloWorld executes the default class constructor ( __init__ ) but not the other methods in the class. Thus, calling the class does not execute the entire content of the class. In fact, executing the entire content of the class is not even a properly defined operation 2 . Calling an object of the class \u00b6 Since HelloWorld has a __call__ method, an instance of the HelloWorld class is also a callable . Python y () # 1 Again, calling y only executes the contents of the HelloWorld.__call__ method. It does not execute the contents of __init__ method (aka the class constructor) or any of the other class methods. The two examples above help disassociate the notion of calling an entity from executing the contents of an entity . Calling an entity has multiple semantics. Simple Function \u00b6 We need some terminology to distinguish functions that have different calling semantics. Simple Function A function is a simple function if calling the function executes the contents of the function. In other words, the calling stage is the same as the execution stage for a simple function. A simple function is the ubiquitous function that every modern day programmer learns. For example, square is a simple function. Suspendable function cannot be a simple function \u00b6 We suspected that this might be the case since Footnote 1 of the previous section. This is best described by a simpler counter example \u2014 let's assume that a suspendable function can indeed be expressed as a simple function in the following pseudocode: Pseudocode suspendable function count_hello : count = 0 while true : count = count + 1 print string ( count ) + \" hello\" release control # to caller count_hello () # 1 hello count_hello () # 2 hello count_hello () # 3 hello The above pseudocode has a few problems: A fourth call to count_hello would inevitably result in 4 hello . There is no way to reset the state back to 1 hello . We're stuck! What if we wanted to have two instances of count_hello simultaneously, possibly at different states? What if we wanted to receive 1 hello as returned value instead of just being printed? When we execute the contents of a suspendable function , we create an internal state for that particular chain of execution. This internal state needs to be stored somewhere. If we then need to initiate a second execution of the same suspendable function , we need to find a different place to store the separate internal state of this second chain of execution. A simple function can maintain at most one internal state 3 . Unless global variables are involved, every call to a simple function is independent of each other, and as a result simple functions do not suffer from the problems mentioned above. Suspendable function \u2260 Simple function Unlike a simple function, calling a suspendable function should not execute its contents. Later in the course, we will see how exactly a suspendable function would come to differ from a simple function. Suspendable function implemented as a class \u00b6 Being able to independentally execute different instances of the same code is the hallmark of object oriented programming. We could easily define count_hello as the following python class. Python class CountHello : def __init__ ( self ): self . count = 0 def run ( self ): self . count = self . count + 1 print ( str ( self . count ) + \" hello\" ) We can now instantiate multiple instances of CountHello , each with its own independent state. Python z = CountHello () w = CountHello () z . run () # 1 hello z . run () # 2 hello z . run () # 3 hello w . run () # 1 hello z . run () # 4 hello The above code is proper Python code. We didn't need to use any fancy keywords to indicate a transfer of control. Each call to CountHello.run performs one iteration that increases the value of count by 1 and then returns the control back to the caller. The state count is preserved between calls to CountHello.run . The actual python code in the CountHello class performs the same work as the pseudocode suspendable function count_hello but without needing any notion of suspendability. Question Why do we even need suspendable functions at all if we can just use classes? The answer to this question is anti-climactic: suspendable entities are not essential . We could do asynchronous programming using other constructs such as classes or callbacks. In fact, the above CountHello class is a rudimentary implementation of a python generator, which we will study later in the course. The benefit of using a suspendable entity (over using a class) is readability, which is highly valued in Python. Callbacks instead of suspendable functions \u00b6 Callbacks provide an alternative approach to perform asynchronous programming, one that is completely independent to suspendables. Callbacks are commonly used in Javascript but also available in python . Though, even in Javascript, callbacks are sometimes considered ugly and async/await is considered easier . These slides , even though about Kotlin, provide an excellent comparison of the callback approach against the coroutine approach. Verbosity & Natural Representation \u00b6 Our pseudocode examples ignored syntax ambiguities. But when programming in python, we want readable, clear, consistent, terse, and unambiguous syntax. Python is popular because of its wonderful syntax and it would be a shame to lose that quality simply to write an asynchronous program. A class is much more verbose than a function. A class requires boilerplate code (such as constructors) which is not needed for a function. For our toy example, the class CountHello does not seem to be much more verbose than the function count_hello but the class-equivalent for a moderate sized suspendable task could be quite verbose. A functional form is also a more natural way to express many forms of computation. Consider the suspendable psedudocode function mashed_potatoes , discussed previously . This function has one control transfer point. We can create a non-suspendable class out of the suspendable mashed_potatoes by splitting the code before and after the control transfer point. Suspendable Function Form Non-suspendable Class Form Pseudocode suspendable function mashed_potatoes ( minutes , auto_shutoff ): peel_potatoes () cut_potatoes () start_boiling_potatoes ( minutes = minutes , auto_shutoff = auto_shutoff ) release control # to the caller finish_boiling_potatoes () mash_potatoes () stir_potatoes_with_butter () Python class MashedPotatoes : def __init__ ( self , minutes , auto_shutoff ): self . minutes = minutes self . auto_shutoff = auto_shutoff def before_control_transfer (): peel_potatoes () cut_potatoes () start_boiling_potatoes ( minutes = 15 , auto_shutoff = true ) def after_control_transfer (): finish_boiling_potatoes () mash_potatoes () stir_potatoes_with_butter () It may be argued that adding a few new keywords to legalize the syntax for a suspendable function is better than having to create a class every time we want to suspend control. mashed_potatoes MashedPotatoes Very little boilerplate code More boilerplate code (such as constructor) Pseudocode Proper python code Needs release & control words No special keywords needed Order of computation is specified by the function itself User needs to remember to order of computation: before_control_transfer() \u2192 after_control_transfer() Extended Function \u00b6 The above discussion may be summarized into the following two points. A suspendable function cannot be a simple function We prefer a suspendable function over classes or callbacks This leads us to define a new type of function. Extended Function A function is an extended function if calling the function does not execute the contents of the function. Executing the contents of the function requires an execution stage beyond the calling stage . Allowing a function to have yet another stage (beyond the defining and calling stage) lets us solve all of our problems albeit at the cost of increased complexity. This concept of an extended function is best described via an example. Python # Stage 1: Defining stage def example (): print ( \"Executing contents of example\" ) yield 1 type ( example ) # function # Stage 2: Calling stage x = example () type ( x ) # generator # Stage 3: Execution stage y = next ( x ) # Executing contents of example print ( y ) # 1 The above example requires a lot of explanation, which we will provide in the Generators section later in the course. For now, this example serves to demonstrate that calling example neither prints Executing contents of example nor provides 1 as a return value. Instead, calling example simply returns a generator object. Executing the contents of example requires yet another step \u2014 calling next on the generator object x . Evidently, the extended function example is very different from the simple function square . The extended function example has one extra stage \u2014 the execution stage. Wary readers may notice that calling example is reminiscent of calling the constructor of a class. This is precisely true! Every invocation example() produces a separate, independent generator object. The function example serves as a concise form of class declaration. In other words, an extended function (such as example ) may be thought of as verbosity-reducing syntactic sugar over a class declaration. This is not the only example of trickery that hides complexity behind syntactical brevity . A very similar construct is a context manager decorator , which allows us to define a context manager as a function instead of having to write a class with boilerplate methods. Arguably, hiding complexity behind syntactical brevity is a defining feature of python itself. Footnotes \u00b6 Though, the syntax of the contents of the function is checked. \u21a9 In order to properly define what it means to execute the entire content of a class, we will need to first some answer questions, such as \u2014 what's the order in which various class methods are executed the arguments and which arguments need to be passed to the class methods. \u21a9 A simple function may use a global variable to save some internal state . This global variable may be accessible by future function invocations or even by other functions. Thus, a simple function using a global variable to maintain an internal state suffers from the same problems outlined above. This is one of the reasons why global variables are considered a bad programming practive . \u21a9","title":"Syntax"},{"location":"suspendables/syntax/#syntax","text":"Syntax What syntax is needed to correctly define a suspendable entity ? We have previously noticed that the syntax we used was janky, even for pseudocode.","title":"Syntax"},{"location":"suspendables/syntax/#function","text":"Let's begin with a relevant albeit non-traditional definition of a function. Function A function is a packaged unit of code that has at least two stages: 1. defining stage 2. calling stage These two stages are so trivial that one may wonder why are we even discussing it. Hopefully, the necessity of this discussion will soon become clear.","title":"Function"},{"location":"suspendables/syntax/#defining-stage","text":"A function may be defined by executing code such as the following. Python def square ( x ): x_squared = x ** 2 return x Executing the above code doesn't actually execute the contents of square 1 . In fact, when we execute the above code, we don't even know which value of x needs to be squared. Thus, it would not even make sense to execute the contents of square while defining it.","title":"Defining stage"},{"location":"suspendables/syntax/#calling-stage","text":"The function square can be called like so: Python square ( 2 ) # 4 Calling a function means executing a code snippet of the form function_name(optional_args) . It just so happens that calling square executes the contents of square . This may sound torturedly pedantic. After all, what else could we possibly mean by calling a function ? It turns out that there may be situations where calling an entity may not necessarily execute the contents of the entity.","title":"Calling stage"},{"location":"suspendables/syntax/#call-execute-necessarily","text":"Let's broaden our notion of what it means to call an entity . In python, functions are not the only callable entities.","title":"Call &ne; Execute, necessarily"},{"location":"suspendables/syntax/#calling-a-class","text":"Let's consider the following simple class. Python class HelloWorld (): def __init__ ( self , data ): self . data = data def __repr__ ( self ): return f ' { self . __class__ . __name__ } ( { self . data } )' def __call__ ( self ): return self . data def set ( self , new_data ): self . data = new_data We can call the HelloWorld class just like we could call a simple function. Python y = HelloWorld ( 1 ) Calling HelloWorld executes the default class constructor ( __init__ ) but not the other methods in the class. Thus, calling the class does not execute the entire content of the class. In fact, executing the entire content of the class is not even a properly defined operation 2 .","title":"Calling a class"},{"location":"suspendables/syntax/#calling-an-object-of-the-class","text":"Since HelloWorld has a __call__ method, an instance of the HelloWorld class is also a callable . Python y () # 1 Again, calling y only executes the contents of the HelloWorld.__call__ method. It does not execute the contents of __init__ method (aka the class constructor) or any of the other class methods. The two examples above help disassociate the notion of calling an entity from executing the contents of an entity . Calling an entity has multiple semantics.","title":"Calling an object of the class"},{"location":"suspendables/syntax/#simple-function","text":"We need some terminology to distinguish functions that have different calling semantics. Simple Function A function is a simple function if calling the function executes the contents of the function. In other words, the calling stage is the same as the execution stage for a simple function. A simple function is the ubiquitous function that every modern day programmer learns. For example, square is a simple function.","title":"Simple Function"},{"location":"suspendables/syntax/#suspendable-function-cannot-be-a-simple-function","text":"We suspected that this might be the case since Footnote 1 of the previous section. This is best described by a simpler counter example \u2014 let's assume that a suspendable function can indeed be expressed as a simple function in the following pseudocode: Pseudocode suspendable function count_hello : count = 0 while true : count = count + 1 print string ( count ) + \" hello\" release control # to caller count_hello () # 1 hello count_hello () # 2 hello count_hello () # 3 hello The above pseudocode has a few problems: A fourth call to count_hello would inevitably result in 4 hello . There is no way to reset the state back to 1 hello . We're stuck! What if we wanted to have two instances of count_hello simultaneously, possibly at different states? What if we wanted to receive 1 hello as returned value instead of just being printed? When we execute the contents of a suspendable function , we create an internal state for that particular chain of execution. This internal state needs to be stored somewhere. If we then need to initiate a second execution of the same suspendable function , we need to find a different place to store the separate internal state of this second chain of execution. A simple function can maintain at most one internal state 3 . Unless global variables are involved, every call to a simple function is independent of each other, and as a result simple functions do not suffer from the problems mentioned above. Suspendable function \u2260 Simple function Unlike a simple function, calling a suspendable function should not execute its contents. Later in the course, we will see how exactly a suspendable function would come to differ from a simple function.","title":"Suspendable function cannot be a simple function"},{"location":"suspendables/syntax/#suspendable-function-implemented-as-a-class","text":"Being able to independentally execute different instances of the same code is the hallmark of object oriented programming. We could easily define count_hello as the following python class. Python class CountHello : def __init__ ( self ): self . count = 0 def run ( self ): self . count = self . count + 1 print ( str ( self . count ) + \" hello\" ) We can now instantiate multiple instances of CountHello , each with its own independent state. Python z = CountHello () w = CountHello () z . run () # 1 hello z . run () # 2 hello z . run () # 3 hello w . run () # 1 hello z . run () # 4 hello The above code is proper Python code. We didn't need to use any fancy keywords to indicate a transfer of control. Each call to CountHello.run performs one iteration that increases the value of count by 1 and then returns the control back to the caller. The state count is preserved between calls to CountHello.run . The actual python code in the CountHello class performs the same work as the pseudocode suspendable function count_hello but without needing any notion of suspendability. Question Why do we even need suspendable functions at all if we can just use classes? The answer to this question is anti-climactic: suspendable entities are not essential . We could do asynchronous programming using other constructs such as classes or callbacks. In fact, the above CountHello class is a rudimentary implementation of a python generator, which we will study later in the course. The benefit of using a suspendable entity (over using a class) is readability, which is highly valued in Python.","title":"Suspendable function implemented as a class"},{"location":"suspendables/syntax/#callbacks-instead-of-suspendable-functions","text":"Callbacks provide an alternative approach to perform asynchronous programming, one that is completely independent to suspendables. Callbacks are commonly used in Javascript but also available in python . Though, even in Javascript, callbacks are sometimes considered ugly and async/await is considered easier . These slides , even though about Kotlin, provide an excellent comparison of the callback approach against the coroutine approach.","title":"Callbacks instead of suspendable functions"},{"location":"suspendables/syntax/#verbosity-natural-representation","text":"Our pseudocode examples ignored syntax ambiguities. But when programming in python, we want readable, clear, consistent, terse, and unambiguous syntax. Python is popular because of its wonderful syntax and it would be a shame to lose that quality simply to write an asynchronous program. A class is much more verbose than a function. A class requires boilerplate code (such as constructors) which is not needed for a function. For our toy example, the class CountHello does not seem to be much more verbose than the function count_hello but the class-equivalent for a moderate sized suspendable task could be quite verbose. A functional form is also a more natural way to express many forms of computation. Consider the suspendable psedudocode function mashed_potatoes , discussed previously . This function has one control transfer point. We can create a non-suspendable class out of the suspendable mashed_potatoes by splitting the code before and after the control transfer point. Suspendable Function Form Non-suspendable Class Form Pseudocode suspendable function mashed_potatoes ( minutes , auto_shutoff ): peel_potatoes () cut_potatoes () start_boiling_potatoes ( minutes = minutes , auto_shutoff = auto_shutoff ) release control # to the caller finish_boiling_potatoes () mash_potatoes () stir_potatoes_with_butter () Python class MashedPotatoes : def __init__ ( self , minutes , auto_shutoff ): self . minutes = minutes self . auto_shutoff = auto_shutoff def before_control_transfer (): peel_potatoes () cut_potatoes () start_boiling_potatoes ( minutes = 15 , auto_shutoff = true ) def after_control_transfer (): finish_boiling_potatoes () mash_potatoes () stir_potatoes_with_butter () It may be argued that adding a few new keywords to legalize the syntax for a suspendable function is better than having to create a class every time we want to suspend control. mashed_potatoes MashedPotatoes Very little boilerplate code More boilerplate code (such as constructor) Pseudocode Proper python code Needs release & control words No special keywords needed Order of computation is specified by the function itself User needs to remember to order of computation: before_control_transfer() \u2192 after_control_transfer()","title":"Verbosity &amp; Natural Representation"},{"location":"suspendables/syntax/#extended-function","text":"The above discussion may be summarized into the following two points. A suspendable function cannot be a simple function We prefer a suspendable function over classes or callbacks This leads us to define a new type of function. Extended Function A function is an extended function if calling the function does not execute the contents of the function. Executing the contents of the function requires an execution stage beyond the calling stage . Allowing a function to have yet another stage (beyond the defining and calling stage) lets us solve all of our problems albeit at the cost of increased complexity. This concept of an extended function is best described via an example. Python # Stage 1: Defining stage def example (): print ( \"Executing contents of example\" ) yield 1 type ( example ) # function # Stage 2: Calling stage x = example () type ( x ) # generator # Stage 3: Execution stage y = next ( x ) # Executing contents of example print ( y ) # 1 The above example requires a lot of explanation, which we will provide in the Generators section later in the course. For now, this example serves to demonstrate that calling example neither prints Executing contents of example nor provides 1 as a return value. Instead, calling example simply returns a generator object. Executing the contents of example requires yet another step \u2014 calling next on the generator object x . Evidently, the extended function example is very different from the simple function square . The extended function example has one extra stage \u2014 the execution stage. Wary readers may notice that calling example is reminiscent of calling the constructor of a class. This is precisely true! Every invocation example() produces a separate, independent generator object. The function example serves as a concise form of class declaration. In other words, an extended function (such as example ) may be thought of as verbosity-reducing syntactic sugar over a class declaration. This is not the only example of trickery that hides complexity behind syntactical brevity . A very similar construct is a context manager decorator , which allows us to define a context manager as a function instead of having to write a class with boilerplate methods. Arguably, hiding complexity behind syntactical brevity is a defining feature of python itself.","title":"Extended Function"},{"location":"suspendables/syntax/#footnotes","text":"Though, the syntax of the contents of the function is checked. \u21a9 In order to properly define what it means to execute the entire content of a class, we will need to first some answer questions, such as \u2014 what's the order in which various class methods are executed the arguments and which arguments need to be passed to the class methods. \u21a9 A simple function may use a global variable to save some internal state . This global variable may be accessible by future function invocations or even by other functions. Thus, a simple function using a global variable to maintain an internal state suffers from the same problems outlined above. This is one of the reasons why global variables are considered a bad programming practive . \u21a9","title":"Footnotes"}]}